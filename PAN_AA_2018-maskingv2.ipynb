{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para o PAN - Atribuição Autoral - 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#python basic libs\n",
    "from __future__ import print_function\n",
    "\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "import os;\n",
    "from os.path import join as pathjoin;\n",
    "\n",
    "import re;\n",
    "import glob;\n",
    "import json;\n",
    "import codecs;\n",
    "from collections import defaultdict;\n",
    "import pprint;\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "\n",
    "#data analysis libs\n",
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt;\n",
    "import random;\n",
    "\n",
    "#machine learning libs\n",
    "#feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#preprocessing and transformation\n",
    "from sklearn.preprocessing import normalize, MaxAbsScaler, MinMaxScaler;\n",
    "from sklearn.preprocessing import LabelBinarizer;\n",
    "from sklearn.decomposition import PCA;\n",
    "from sklearn.metrics.pairwise import cosine_similarity;\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "#classifiers\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFE,SelectFpr,SelectPercentile, chi2;\n",
    "\n",
    "#\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#model valuation\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns;\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darwin-17.5.0-x86_64-i386-64bit\n",
      "NumPy 1.14.2\n",
      "SciPy 1.0.1\n",
      "Scikit-Learn 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "print(\"NumPy\", np.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paths configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = '/Users/joseeleandrocustodio/Dropbox/mestrado/02 - Pesquisa/code';\n",
    "\n",
    "inputDir= pathjoin(baseDir,'pan18aa');\n",
    "outputDir= pathjoin(baseDir,'out',\"oficial\");\n",
    "if not os.path.exists(outputDir):\n",
    "    os.mkdir(outputDir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCollectionsOfProblems(path):\n",
    "    # Reading information about the collection\n",
    "    infocollection = path+os.sep+'collection-info.json'\n",
    "    with open(infocollection, 'r') as f:\n",
    "        problems  = [\n",
    "            {\n",
    "                'problem': attrib['problem-name'],\n",
    "                'language': attrib['language'],\n",
    "                'encoding': attrib['encoding'],\n",
    "            }\n",
    "            for attrib in json.load(f)\n",
    "            \n",
    "        ]\n",
    "    return problems;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = readCollectionsOfProblems(inputDir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': u'UTF-8', 'language': u'en', 'problem': u'problem00001'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readProblem(path, problem):\n",
    "    # Reading information about the problem\n",
    "    infoproblem = path+os.sep+problem+os.sep+'problem-info.json'\n",
    "    candidates = []\n",
    "    with open(infoproblem, 'r') as f:\n",
    "        fj = json.load(f)\n",
    "        unk_folder = fj['unknown-folder']\n",
    "        for attrib in fj['candidate-authors']:\n",
    "            candidates.append(attrib['author-name'])\n",
    "    return unk_folder, candidates;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path,label):\n",
    "    # Reads all text files located in the 'path' and assigns them to 'label' class\n",
    "    files = glob.glob(pathjoin(path,label,'*.txt'))\n",
    "    texts=[]\n",
    "    for i,v in enumerate(files):\n",
    "        f=codecs.open(v,'r',encoding='utf-8')\n",
    "        texts.append((f.read(),label, os.path.basename(v)))\n",
    "        f.close()\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index,problem in enumerate(problems):\n",
    "    unk_folder, candidates_folder = readProblem(inputDir, problem['problem']); \n",
    "    problem['candidates_folder_count'] = len(candidates_folder);\n",
    "    problem['candidates'] = [];\n",
    "    for candidate in candidates_folder:\n",
    "        problem['candidates'].extend(read_files(pathjoin(inputDir, problem['problem']),candidate));\n",
    "    \n",
    "    problem['unknown'] = read_files(pathjoin(inputDir, problem['problem']),unk_folder);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidates</th>\n",
       "      <th>candidates_folder_count</th>\n",
       "      <th>encoding</th>\n",
       "      <th>language</th>\n",
       "      <th>problem</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(graceful ones.\\n\\n\"One more,\" Marvelous said...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>en</td>\n",
       "      <td>problem00001</td>\n",
       "      <td>[(after all, his best friends. And what in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(a mission.\"\\n\\nJensen just raises an eyebrow...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>en</td>\n",
       "      <td>problem00002</td>\n",
       "      <td>[(“Potter was attractive,” Draco thought, sigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(qui l'avait tué mais tout était de la faute ...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>fr</td>\n",
       "      <td>problem00003</td>\n",
       "      <td>[(son réveil. Sa main pulse et Draco frotte l'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(. Le canapé est vide et lorsqu'il passe deva...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>fr</td>\n",
       "      <td>problem00004</td>\n",
       "      <td>[(abasourdie.\\n\\nTout d'abord, elle crut que s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(Eppure lui la mappa l’aveva stampata, dannaz...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>it</td>\n",
       "      <td>problem00005</td>\n",
       "      <td>[(– Oh. Cazzo.\\nSirius era così sconvolto che ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[(Yato ha trovato una lettera sul suo comodino...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>it</td>\n",
       "      <td>problem00006</td>\n",
       "      <td>[(così la tua vista, Moony?\\n– Cercavo di esse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[(zmienił zdanie. Niech się stworzonko pobawi....</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>pl</td>\n",
       "      <td>problem00007</td>\n",
       "      <td>[(dawniej pełna radości i ciepła, a teraz wiec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[(Słowem, które Sherlock najczęściej słyszał w...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>pl</td>\n",
       "      <td>problem00008</td>\n",
       "      <td>[(, uderzającego o żebra niczym dzwon- niemal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[(pero no lo ama como ama a Guignol –explicó e...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>sp</td>\n",
       "      <td>problem00009</td>\n",
       "      <td>[(–La nariz puntiaguda del elfo casi rozaba el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[(incapaz de señalar un momento exacto, un pun...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>sp</td>\n",
       "      <td>problem00010</td>\n",
       "      <td>[(tan parecidas hizo que su trasero latiese de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          candidates  candidates_folder_count  \\\n",
       "0  [(graceful ones.\\n\\n\"One more,\" Marvelous said...                       20   \n",
       "1  [(a mission.\"\\n\\nJensen just raises an eyebrow...                        5   \n",
       "2  [(qui l'avait tué mais tout était de la faute ...                       20   \n",
       "3  [(. Le canapé est vide et lorsqu'il passe deva...                        5   \n",
       "4  [(Eppure lui la mappa l’aveva stampata, dannaz...                       20   \n",
       "5  [(Yato ha trovato una lettera sul suo comodino...                        5   \n",
       "6  [(zmienił zdanie. Niech się stworzonko pobawi....                       20   \n",
       "7  [(Słowem, które Sherlock najczęściej słyszał w...                        5   \n",
       "8  [(pero no lo ama como ama a Guignol –explicó e...                       20   \n",
       "9  [(incapaz de señalar un momento exacto, un pun...                        5   \n",
       "\n",
       "  encoding language       problem  \\\n",
       "0    UTF-8       en  problem00001   \n",
       "1    UTF-8       en  problem00002   \n",
       "2    UTF-8       fr  problem00003   \n",
       "3    UTF-8       fr  problem00004   \n",
       "4    UTF-8       it  problem00005   \n",
       "5    UTF-8       it  problem00006   \n",
       "6    UTF-8       pl  problem00007   \n",
       "7    UTF-8       pl  problem00008   \n",
       "8    UTF-8       sp  problem00009   \n",
       "9    UTF-8       sp  problem00010   \n",
       "\n",
       "                                             unknown  \n",
       "0  [(after all, his best friends. And what in the...  \n",
       "1  [(“Potter was attractive,” Draco thought, sigh...  \n",
       "2  [(son réveil. Sa main pulse et Draco frotte l'...  \n",
       "3  [(abasourdie.\\n\\nTout d'abord, elle crut que s...  \n",
       "4  [(– Oh. Cazzo.\\nSirius era così sconvolto che ...  \n",
       "5  [(così la tua vista, Moony?\\n– Cercavo di esse...  \n",
       "6  [(dawniej pełna radości i ciepła, a teraz wiec...  \n",
       "7  [(, uderzającego o żebra niczym dzwon- niemal ...  \n",
       "8  [(–La nariz puntiaguda del elfo casi rozaba el...  \n",
       "9  [(tan parecidas hizo que su trasero latiese de...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************************************************************************\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def eval_measures(gt, pred):\n",
    "    \"\"\"Compute macro-averaged F1-scores, macro-averaged precision, \n",
    "    macro-averaged recall, and micro-averaged accuracy according the ad hoc\n",
    "    rules discussed at the top of this file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt : dict\n",
    "        Ground truth, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    pred : dict\n",
    "        Predicted attribution, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    Returns\n",
    "    -------\n",
    "    f1 : float\n",
    "        Macro-averaged F1-score\n",
    "    precision : float\n",
    "        Macro-averaged precision\n",
    "    recall : float\n",
    "        Macro-averaged recall\n",
    "    accuracy : float\n",
    "        Micro-averaged F1-score\n",
    "    \"\"\"\n",
    "\n",
    "    actual_authors = list(gt.values())\n",
    "    encoder = LabelEncoder().fit(['<UNK>'] + actual_authors)\n",
    "\n",
    "    text_ids, gold_authors, silver_authors = [], [], []\n",
    "    for text_id in sorted(gt):\n",
    "        text_ids.append(text_id)\n",
    "        gold_authors.append(gt[text_id])\n",
    "        try:\n",
    "            silver_authors.append(pred[text_id])\n",
    "        except KeyError:\n",
    "            # missing attributions get <UNK>:\n",
    "            silver_authors.append('<UNK>')\n",
    "\n",
    "    assert len(text_ids) == len(gold_authors)\n",
    "    assert len(text_ids) == len(silver_authors)\n",
    "\n",
    "    # replace non-existent silver authors with '<UNK>':\n",
    "    silver_authors = [a if a in encoder.classes_ else '<UNK>' \n",
    "                      for a in silver_authors]\n",
    "\n",
    "    gold_author_ints   = encoder.transform(gold_authors)\n",
    "    silver_author_ints = encoder.transform(silver_authors)\n",
    "\n",
    "    # get F1 for individual classes (and suppress warnings):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        f1 = f1_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels=list(set(gold_author_ints)),\n",
    "                  average='macro')\n",
    "        precision = precision_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels=list(set(gold_author_ints)),\n",
    "                  average='macro')\n",
    "        recall = recall_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels=list(set(gold_author_ints)),\n",
    "                  average='macro')\n",
    "        accuracy = accuracy_score(gold_author_ints,\n",
    "                  silver_author_ints)\n",
    "\n",
    "    return f1,precision,recall,accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth_file,predictions_file):\n",
    "    # Calculates evaluation measures for a single attribution problem\n",
    "    gt = {}\n",
    "    with open(ground_truth_file, 'r') as f:\n",
    "        for attrib in json.load(f)['ground_truth']:\n",
    "            gt[attrib['unknown-text']] = attrib['true-author']\n",
    "\n",
    "    pred = {}\n",
    "    with open(predictions_file, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            if attrib['unknown-text'] not in pred:\n",
    "                pred[attrib['unknown-text']] = attrib['predicted-author']\n",
    "    f1,precision,recall,accuracy =  eval_measures(gt,pred)\n",
    "    return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    \"\"\"Convert a sparse array into a dense array.\"\"\"\n",
    "\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\" Return a dense version of the input array.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples] (default: None)\n",
    "        Returns\n",
    "        ---------\n",
    "        X_dense : dense version of the input X array.\n",
    "        \"\"\"\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" Mock method. Does nothing.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples] (default: None)\n",
    "        Returns\n",
    "        ---------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\" Return a dense version of the input array.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples] (default: None)\n",
    "        Returns\n",
    "        ---------\n",
    "        X_dense : dense version of the input X array.\n",
    "        \"\"\"\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "class ObfuscationTransformer(BaseEstimator):\n",
    "    def __init__(self,re_from=r'(\\b)(\\w{0,2})\\w+(\\w{1,3})(\\b)', re_to=r'\\1\\2XX\\3\\4', return_copy=True):\n",
    "        self.re_from = re_from\n",
    "        self.re_to = re_to\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = np.array(X).copy();\n",
    "        for i in range(len(X)):\n",
    "            X[i] = re.sub(self.re_from,self.re_to, X[i])\n",
    "        \n",
    "        return X;\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examinando o parametro min_df isoladamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runML(problem):\n",
    "    print (\"\\nProblem: %s,  language: %s, \" %(problem['problem'],problem['language']))\n",
    "    \n",
    "    train_docs, train_labels, _   = zip(*problem['candidates'])\n",
    "    problem['training_docs_size'] = len(train_docs);\n",
    "    test_docs, _, test_filename   = zip(*problem['unknown'])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('obs',ObfuscationTransformer(re_from=r'\\w',re_to='x')),\n",
    "        ('vect',   TfidfVectorizer(analyzer='char',\n",
    "                                   min_df=0.01,\n",
    "                                   max_df=1.0,\n",
    "                                   norm='l1',\n",
    "                                   ngram_range=(3,5),\n",
    "                                   sublinear_tf=True,\n",
    "                                   smooth_idf=True,\n",
    "                                   lowercase =False)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # uncommenting more parameters will give better exploring power but will\n",
    "    # increase processing time in a combinatorial way\n",
    "    parameters = {\n",
    "        'vect__min_df':(2,0.01,0.05,0.1)\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline,\n",
    "                               parameters,\n",
    "                               cv=5,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=False,\n",
    "                               scoring='f1_macro')\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, train_labels)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    train_pred=grid_search.predict(train_docs);\n",
    "    test_pred=grid_search.predict(test_docs);\n",
    "    \n",
    "    \n",
    "    # Writing output file\n",
    "    out_data=[]\n",
    "    for i,v in enumerate(test_pred):\n",
    "        out_data.append({'unknown-text': test_filename[i],'predicted-author': v})\n",
    "    answerFile = pathjoin(outputDir,'answers-'+problem['problem']+'.json');\n",
    "    with open(answerFile, 'w') as f:\n",
    "        json.dump(out_data, f, indent=4)\n",
    "    \n",
    "    \n",
    "    #evaluation train\n",
    "    f1,precision,recall,accuracy=evaluate(\n",
    "                pathjoin(inputDir, problem['problem'], 'ground-truth.json'),\n",
    "                answerFile)\n",
    "    \n",
    "    return {\n",
    "                'problem-name'  :       problem['problem'],\n",
    "                \"language\"      :       problem['language'],\n",
    "                'AuthorCount'   :       len(set(train_labels)),\n",
    "                \"train_doc_size\":       len(train_docs),\n",
    "                \"train_caract_per_doc\": sum([len(l) for l in train_docs])/len(train_docs),\n",
    "                \"test_doc_size\" :       len(test_docs),\n",
    "                \"test_caract_per_doc\":  sum([len(l) for l in test_docs])/len(test_docs),\n",
    "                \n",
    "                'macro-f1'       : round(f1,3),\n",
    "                'macro-precision': round(precision,3),\n",
    "                'macro-recall'   : round(recall,3),\n",
    "                'micro-accuracy' : round(accuracy,3),\n",
    "                \n",
    "        }, grid_search.cv_results_, best_parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: problem00001,  language: en, \n",
      "Performing grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 26.488s\n",
      "Best score: 0.612\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00002,  language: en, \n",
      "Performing grid search...\n",
      "done in 7.856s\n",
      "Best score: 0.871\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00003,  language: fr, \n",
      "Performing grid search...\n",
      "done in 31.069s\n",
      "Best score: 0.651\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00004,  language: fr, \n",
      "Performing grid search...\n",
      "done in 8.112s\n",
      "Best score: 0.570\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00005,  language: it, \n",
      "Performing grid search...\n",
      "done in 35.381s\n",
      "Best score: 0.651\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00006,  language: it, \n",
      "Performing grid search...\n",
      "done in 8.401s\n",
      "Best score: 0.796\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.1\n",
      "\n",
      "Problem: problem00007,  language: pl, \n",
      "Performing grid search...\n",
      "done in 40.481s\n",
      "Best score: 0.756\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.05\n",
      "\n",
      "Problem: problem00008,  language: pl, \n",
      "Performing grid search...\n",
      "done in 8.826s\n",
      "Best score: 0.931\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00009,  language: sp, \n",
      "Performing grid search...\n",
      "done in 32.578s\n",
      "Best score: 0.700\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00010,  language: sp, \n",
      "Performing grid search...\n",
      "done in 8.246s\n",
      "Best score: 0.619\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n"
     ]
    }
   ],
   "source": [
    "result = [];\n",
    "cv_result = [];\n",
    "best_parameters = [];\n",
    "for problem in problems:\n",
    "    r, c, b = runML(problem);\n",
    "    result.append(r);\n",
    "    cv_result.append(c);\n",
    "    b['problem'] = problem['problem'];\n",
    "    best_parameters.append(b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>vect__min_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem00001</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem00002</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem00003</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem00004</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem00005</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem00006</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>problem00007</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>problem00008</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>problem00009</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>problem00010</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        problem  vect__min_df\n",
       "0  problem00001          0.01\n",
       "1  problem00002          2.00\n",
       "2  problem00003          2.00\n",
       "3  problem00004          0.01\n",
       "4  problem00005          2.00\n",
       "5  problem00006          0.10\n",
       "6  problem00007          0.05\n",
       "7  problem00008          2.00\n",
       "8  problem00009          0.01\n",
       "9  problem00010          0.01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(best_parameters)[['problem','vect__min_df']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analisando os demais parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runML(problem):\n",
    "    print (\"\\nProblem: %s,  language: %s, \" %(problem['problem'],problem['language']))\n",
    "    \n",
    "    train_docs, train_labels, _   = zip(*problem['candidates'])\n",
    "    problem['training_docs_size'] = len(train_docs);\n",
    "    test_docs, _, test_filename   = zip(*problem['unknown'])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('obs',ObfuscationTransformer(re_from=r'\\w',re_to='x')),\n",
    "        ('vect',   TfidfVectorizer(analyzer='char',\n",
    "                                   min_df=0.01,\n",
    "                                   max_df=1.0,\n",
    "                                   norm='l1',\n",
    "                                   lowercase =False,\n",
    "                                   sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA()),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # uncommenting more parameters will give better exploring power but will\n",
    "    # increase processing time in a combinatorial way\n",
    "    parameters = {\n",
    "        'vect__ngram_range':((2,3),(2,4),(2,5),(3,5)),\n",
    "        'vect__sublinear_tf':(True, False),\n",
    "        'transf__n_components': (0.1,0.5,0.9,0.999),\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline,\n",
    "                               parameters,\n",
    "                               cv=5,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=False,\n",
    "                               scoring='f1_macro')\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, train_labels)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    train_pred=grid_search.predict(train_docs);\n",
    "    test_pred=grid_search.predict(test_docs);\n",
    "    \n",
    "    \n",
    "    # Writing output file\n",
    "    out_data=[]\n",
    "    for i,v in enumerate(test_pred):\n",
    "        out_data.append({'unknown-text': test_filename[i],'predicted-author': v})\n",
    "    answerFile = pathjoin(outputDir,'answers-'+problem['problem']+'.json');\n",
    "    with open(answerFile, 'w') as f:\n",
    "        json.dump(out_data, f, indent=4)\n",
    "    \n",
    "    \n",
    "    #evaluation train\n",
    "    f1,precision,recall,accuracy=evaluate(\n",
    "                pathjoin(inputDir, problem['problem'], 'ground-truth.json'),\n",
    "                answerFile)\n",
    "    \n",
    "    return {\n",
    "                'problem-name'  :       problem['problem'],\n",
    "                \"language\"      :       problem['language'],\n",
    "                'AuthorCount'   :       len(set(train_labels)),\n",
    "                \"train_doc_size\":       len(train_docs),\n",
    "                \"train_caract_per_doc\": sum([len(l) for l in train_docs])/len(train_docs),\n",
    "                \"test_doc_size\" :       len(test_docs),\n",
    "                \"test_caract_per_doc\":  sum([len(l) for l in test_docs])/len(test_docs),\n",
    "                \n",
    "                'macro-f1'       : round(f1,3),\n",
    "                'macro-precision': round(precision,3),\n",
    "                'macro-recall'   : round(recall,3),\n",
    "                'micro-accuracy' : round(accuracy,3),\n",
    "                \n",
    "        }, grid_search.cv_results_,best_parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: problem00001,  language: en, \n",
      "Performing grid search...\n",
      "done in 209.749s\n",
      "Best score: 0.637\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (2, 5)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00002,  language: en, \n",
      "Performing grid search...\n",
      "done in 53.201s\n",
      "Best score: 0.943\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.999\n",
      "\tvect__ngram_range: (2, 3)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00003,  language: fr, \n",
      "Performing grid search...\n",
      "done in 221.275s\n",
      "Best score: 0.661\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.999\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00004,  language: fr, \n",
      "Performing grid search...\n",
      "done in 59.277s\n",
      "Best score: 0.636\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.999\n",
      "\tvect__ngram_range: (3, 5)\n",
      "\tvect__sublinear_tf: False\n",
      "\n",
      "Problem: problem00005,  language: it, \n",
      "Performing grid search...\n",
      "done in 254.150s\n",
      "Best score: 0.650\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00006,  language: it, \n",
      "Performing grid search...\n",
      "done in 62.037s\n",
      "Best score: 0.834\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: False\n",
      "\n",
      "Problem: problem00007,  language: pl, \n",
      "Performing grid search...\n",
      "done in 268.741s\n",
      "Best score: 0.754\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (3, 5)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00008,  language: pl, \n",
      "Performing grid search...\n",
      "done in 81.555s\n",
      "Best score: 0.931\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (2, 5)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00009,  language: sp, \n",
      "Performing grid search...\n",
      "done in 274.019s\n",
      "Best score: 0.709\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00010,  language: sp, \n",
      "Performing grid search...\n",
      "done in 67.243s\n",
      "Best score: 0.660\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.5\n",
      "\tvect__ngram_range: (2, 5)\n",
      "\tvect__sublinear_tf: True\n"
     ]
    }
   ],
   "source": [
    "result = [];\n",
    "cv_result = [];\n",
    "best_parameters = [];\n",
    "for problem in problems:\n",
    "    r, c, b = runML(problem);\n",
    "    result.append(r);\n",
    "    cv_result.append(c);\n",
    "    b['problem'] = problem['problem'];\n",
    "    best_parameters.append(b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(result)[['problem-name',\n",
    "                     \"language\",\n",
    "                     'AuthorCount',\n",
    "                     \"train_doc_size\",\"train_caract_per_doc\",\n",
    "                     \"test_doc_size\", \"test_caract_per_doc\",\n",
    "                     'macro-f1','macro-precision','macro-recall' ,'micro-accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem-name</th>\n",
       "      <th>language</th>\n",
       "      <th>AuthorCount</th>\n",
       "      <th>train_doc_size</th>\n",
       "      <th>train_caract_per_doc</th>\n",
       "      <th>test_doc_size</th>\n",
       "      <th>test_caract_per_doc</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>macro-precision</th>\n",
       "      <th>macro-recall</th>\n",
       "      <th>micro-accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem00001</td>\n",
       "      <td>en</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4327</td>\n",
       "      <td>105</td>\n",
       "      <td>4370</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem00002</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4342</td>\n",
       "      <td>21</td>\n",
       "      <td>4296</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem00003</td>\n",
       "      <td>fr</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4492</td>\n",
       "      <td>49</td>\n",
       "      <td>4508</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem00004</td>\n",
       "      <td>fr</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4522</td>\n",
       "      <td>21</td>\n",
       "      <td>4532</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem00005</td>\n",
       "      <td>it</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4720</td>\n",
       "      <td>80</td>\n",
       "      <td>4787</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem00006</td>\n",
       "      <td>it</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4847</td>\n",
       "      <td>46</td>\n",
       "      <td>4765</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>problem00007</td>\n",
       "      <td>pl</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>5145</td>\n",
       "      <td>103</td>\n",
       "      <td>5200</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>problem00008</td>\n",
       "      <td>pl</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>5049</td>\n",
       "      <td>15</td>\n",
       "      <td>5214</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>problem00009</td>\n",
       "      <td>sp</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4794</td>\n",
       "      <td>117</td>\n",
       "      <td>4788</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>problem00010</td>\n",
       "      <td>sp</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4955</td>\n",
       "      <td>64</td>\n",
       "      <td>4827</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem-name language  AuthorCount  train_doc_size  train_caract_per_doc  \\\n",
       "0  problem00001       en           20             140                  4327   \n",
       "1  problem00002       en            5              35                  4342   \n",
       "2  problem00003       fr           20             140                  4492   \n",
       "3  problem00004       fr            5              35                  4522   \n",
       "4  problem00005       it           20             140                  4720   \n",
       "5  problem00006       it            5              35                  4847   \n",
       "6  problem00007       pl           20             140                  5145   \n",
       "7  problem00008       pl            5              35                  5049   \n",
       "8  problem00009       sp           20             140                  4794   \n",
       "9  problem00010       sp            5              35                  4955   \n",
       "\n",
       "   test_doc_size  test_caract_per_doc  macro-f1  macro-precision  \\\n",
       "0            105                 4370     0.457            0.437   \n",
       "1             21                 4296     0.337            0.352   \n",
       "2             49                 4508     0.615            0.629   \n",
       "3             21                 4532     0.559            0.650   \n",
       "4             80                 4787     0.454            0.413   \n",
       "5             46                 4765     0.575            0.608   \n",
       "6            103                 5200     0.468            0.485   \n",
       "7             15                 5214     0.556            0.550   \n",
       "8            117                 4788     0.564            0.569   \n",
       "9             64                 4827     0.623            0.651   \n",
       "\n",
       "   macro-recall  micro-accuracy  \n",
       "0         0.627           0.562  \n",
       "1         0.453           0.333  \n",
       "2         0.659           0.633  \n",
       "3         0.707           0.524  \n",
       "4         0.589           0.625  \n",
       "5         0.687           0.804  \n",
       "6         0.527           0.456  \n",
       "7         0.711           0.667  \n",
       "8         0.638           0.598  \n",
       "9         0.683           0.656  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rr}\n",
      "\\toprule\n",
      " index &  macro-f1 \\\\\n",
      "\\midrule\n",
      " 0 & 0.457 \\\\\n",
      " 1 & 0.337 \\\\\n",
      " 2 & 0.615 \\\\\n",
      " 3 & 0.559 \\\\\n",
      " 4 & 0.454 \\\\\n",
      " 5 & 0.575 \\\\\n",
      " 6 & 0.468 \\\\\n",
      " 7 & 0.556 \\\\\n",
      " 8 & 0.564 \\\\\n",
      " 9 & 0.623 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"macro-f1\"]].reset_index().to_latex(index=False).replace(\"     \",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages={\n",
    "    'en':'inglesa',\n",
    "    'sp':'espanhola',\n",
    "    'it':'italiana',\n",
    "    'pl':'polonesa',\n",
    "    'fr':'francesa'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result2 = [];\n",
    "dfCV = pd.DataFrame();\n",
    "for i, c in enumerate(cv_result):\n",
    "    temp = pd.DataFrame(c);\n",
    "    temp['problem'] = i+1;\n",
    "    temp['language'] = languages[problems[i]['language']]\n",
    "    dfCV = dfCV.append(temp);\n",
    "\n",
    "for p in ['param_transf__n_components',\n",
    "    'mean_test_score','std_test_score','mean_train_score',   \n",
    "    'split0_test_score','split0_train_score',\n",
    "    'split1_test_score','split1_train_score',\n",
    "    'split2_test_score','split2_train_score',\n",
    "    'split3_test_score','split3_train_score',\n",
    "    'split4_test_score','split4_train_score']:\n",
    "    dfCV[p]=dfCV[p].astype(np.float32);\n",
    "\n",
    "    \n",
    "dfCV =dfCV[[\n",
    "    'problem',\n",
    "    'language',\n",
    "    'rank_test_score',\n",
    "    'param_transf__n_components',\n",
    "    'param_vect__ngram_range',\n",
    "    'param_vect__sublinear_tf',\n",
    "    'mean_test_score',   \n",
    "    'std_test_score',\n",
    "    'mean_train_score',   \n",
    "\n",
    "    'split0_test_score','split0_train_score',\n",
    "    'split1_test_score','split1_train_score',\n",
    "    'split2_test_score','split2_train_score',\n",
    "    'split3_test_score','split3_train_score',\n",
    "    'split4_test_score','split4_train_score',\n",
    "\n",
    "    'mean_score_time',\n",
    "    'mean_fit_time',\n",
    "    'std_fit_time',\n",
    "    'std_score_time',\n",
    "    'std_train_score',\n",
    "]];\n",
    "\n",
    "dfCV.rename(columns={\n",
    "    'param_transf__n_components':'PCA_componentes',\n",
    "    'param_vect__ngram_range':'ngram_range',\n",
    "    'param_vect__sublinear_tf':'sublinear_tf',\n",
    "    'param_vect__smooth_idf':'smooth_idf'\n",
    "},inplace=True);\n",
    "\n",
    "#print('\\',\\n\\''.join(dfCV.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCV.to_csv('PANAA2018_MASK.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>language</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>sublinear_tf</th>\n",
       "      <th>PCA_componentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.094</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.090</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.102</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.193</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>italiana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.054</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>italiana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.143</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.085</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.093</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.093</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.093</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.093</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.093</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.093</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.093</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.059</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.190</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    problem   language  rank_test_score  mean_test_score  std_test_score  \\\n",
       "20        1    inglesa                1            0.637           0.094   \n",
       "24        2    inglesa                1            0.943           0.090   \n",
       "26        3   francesa                1            0.661           0.102   \n",
       "31        4   francesa                1            0.636           0.193   \n",
       "18        5   italiana                1            0.650           0.054   \n",
       "19        6   italiana                1            0.834           0.143   \n",
       "22        7   polonesa                1            0.754           0.085   \n",
       "30        8   polonesa                1            0.931           0.093   \n",
       "22        8   polonesa                1            0.931           0.093   \n",
       "31        8   polonesa                1            0.931           0.093   \n",
       "28        8   polonesa                1            0.931           0.093   \n",
       "20        8   polonesa                1            0.931           0.093   \n",
       "29        8   polonesa                1            0.931           0.093   \n",
       "27        8   polonesa                1            0.931           0.093   \n",
       "18        9  espanhola                1            0.709           0.059   \n",
       "12       10  espanhola                1            0.660           0.190   \n",
       "\n",
       "   ngram_range sublinear_tf  PCA_componentes  \n",
       "20      (2, 5)         True            0.900  \n",
       "24      (2, 3)         True            0.999  \n",
       "26      (2, 4)         True            0.999  \n",
       "31      (3, 5)        False            0.999  \n",
       "18      (2, 4)         True            0.900  \n",
       "19      (2, 4)        False            0.900  \n",
       "22      (3, 5)         True            0.900  \n",
       "30      (3, 5)         True            0.999  \n",
       "22      (3, 5)         True            0.900  \n",
       "31      (3, 5)        False            0.999  \n",
       "28      (2, 5)         True            0.999  \n",
       "20      (2, 5)         True            0.900  \n",
       "29      (2, 5)        False            0.999  \n",
       "27      (2, 4)        False            0.999  \n",
       "18      (2, 4)         True            0.900  \n",
       "12      (2, 5)         True            0.500  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dfCV[dfCV.rank_test_score == 1])[\n",
    "    ['problem',\n",
    "     'language',\n",
    "    'rank_test_score',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "    'ngram_range',\n",
    "    'sublinear_tf',\n",
    "    'PCA_componentes']\n",
    "].sort_values(by=[\n",
    "    'problem',\n",
    "    'mean_test_score',\n",
    "    'ngram_range',\n",
    "    'sublinear_tf',\n",
    "    'PCA_componentes'\n",
    "], ascending=[True, False,False,False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sublinear_tf</th>\n",
       "      <th colspan=\"4\" halign=\"left\">False</th>\n",
       "      <th colspan=\"4\" halign=\"left\">True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>(2, 3)</th>\n",
       "      <th>(2, 4)</th>\n",
       "      <th>(2, 5)</th>\n",
       "      <th>(3, 5)</th>\n",
       "      <th>(2, 3)</th>\n",
       "      <th>(2, 4)</th>\n",
       "      <th>(2, 5)</th>\n",
       "      <th>(3, 5)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem</th>\n",
       "      <th>language</th>\n",
       "      <th>PCA_componentes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">inglesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.094</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.391</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">inglesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.371</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">francesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.142</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">francesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.549</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.477</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">italiana</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.181</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.521</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.581</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.572</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">italiana</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.509</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.766</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">7</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">polonesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.292</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.578</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.616</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">8</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">polonesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.615</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">9</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">espanhola</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.177</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.459</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">espanhola</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.389</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.499</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.556</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.509</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sublinear_tf                       False                       True          \\\n",
       "ngram_range                       (2, 3) (2, 4) (2, 5) (3, 5) (2, 3) (2, 4)   \n",
       "problem language  PCA_componentes                                             \n",
       "1       inglesa   0.100            0.094  0.093  0.088  0.089  0.077  0.082   \n",
       "                  0.500            0.391  0.360  0.431  0.412  0.433  0.496   \n",
       "                  0.900            0.526  0.560  0.566  0.553  0.600  0.619   \n",
       "                  0.999            0.517  0.548  0.542  0.554  0.634  0.630   \n",
       "2       inglesa   0.100            0.371  0.333  0.266  0.295  0.410  0.394   \n",
       "                  0.500            0.672  0.672  0.666  0.666  0.829  0.901   \n",
       "                  0.900            0.741  0.789  0.685  0.618  0.901  0.874   \n",
       "                  0.999            0.800  0.806  0.768  0.817  0.943  0.912   \n",
       "3       francesa  0.100            0.142  0.147  0.194  0.205  0.179  0.202   \n",
       "                  0.500            0.435  0.449  0.506  0.517  0.470  0.488   \n",
       "                  0.900            0.517  0.548  0.502  0.537  0.564  0.621   \n",
       "                  0.999            0.525  0.575  0.570  0.570  0.581  0.661   \n",
       "4       francesa  0.100            0.269  0.207  0.225  0.282  0.202  0.129   \n",
       "                  0.500            0.350  0.419  0.340  0.297  0.388  0.338   \n",
       "                  0.900            0.549  0.544  0.570  0.570  0.537  0.613   \n",
       "                  0.999            0.477  0.603  0.598  0.636  0.604  0.613   \n",
       "5       italiana  0.100            0.181  0.244  0.243  0.236  0.125  0.158   \n",
       "                  0.500            0.521  0.562  0.547  0.529  0.552  0.597   \n",
       "                  0.900            0.581  0.574  0.575  0.568  0.611  0.650   \n",
       "                  0.999            0.572  0.579  0.572  0.566  0.631  0.650   \n",
       "6       italiana  0.100            0.509  0.520  0.634  0.600  0.468  0.484   \n",
       "                  0.500            0.796  0.796  0.796  0.747  0.730  0.697   \n",
       "                  0.900            0.796  0.834  0.806  0.806  0.796  0.796   \n",
       "                  0.999            0.766  0.796  0.796  0.796  0.766  0.766   \n",
       "7       polonesa  0.100            0.292  0.363  0.325  0.378  0.357  0.388   \n",
       "                  0.500            0.516  0.598  0.607  0.594  0.656  0.707   \n",
       "                  0.900            0.578  0.617  0.659  0.671  0.670  0.717   \n",
       "                  0.999            0.616  0.642  0.687  0.680  0.684  0.685   \n",
       "8       polonesa  0.100            0.615  0.514  0.449  0.449  0.430  0.481   \n",
       "                  0.500            0.749  0.834  0.813  0.787  0.893  0.893   \n",
       "                  0.900            0.867  0.905  0.874  0.874  0.893  0.893   \n",
       "                  0.999            0.905  0.931  0.931  0.931  0.893  0.893   \n",
       "9       espanhola 0.100            0.177  0.186  0.234  0.247  0.156  0.188   \n",
       "                  0.500            0.459  0.523  0.547  0.529  0.570  0.568   \n",
       "                  0.900            0.516  0.530  0.538  0.558  0.673  0.709   \n",
       "                  0.999            0.512  0.530  0.584  0.595  0.656  0.695   \n",
       "10      espanhola 0.100            0.389  0.314  0.341  0.447  0.388  0.420   \n",
       "                  0.500            0.499  0.391  0.397  0.371  0.640  0.609   \n",
       "                  0.900            0.556  0.486  0.497  0.545  0.595  0.595   \n",
       "                  0.999            0.509  0.537  0.541  0.528  0.574  0.574   \n",
       "\n",
       "sublinear_tf                                     \n",
       "ngram_range                       (2, 5) (3, 5)  \n",
       "problem language  PCA_componentes                \n",
       "1       inglesa   0.100            0.099  0.103  \n",
       "                  0.500            0.484  0.473  \n",
       "                  0.900            0.637  0.582  \n",
       "                  0.999            0.629  0.612  \n",
       "2       inglesa   0.100            0.363  0.363  \n",
       "                  0.500            0.872  0.872  \n",
       "                  0.900            0.874  0.874  \n",
       "                  0.999            0.874  0.836  \n",
       "3       francesa  0.100            0.198  0.189  \n",
       "                  0.500            0.509  0.552  \n",
       "                  0.900            0.632  0.625  \n",
       "                  0.999            0.644  0.651  \n",
       "4       francesa  0.100            0.148  0.190  \n",
       "                  0.500            0.390  0.383  \n",
       "                  0.900            0.584  0.570  \n",
       "                  0.999            0.587  0.570  \n",
       "5       italiana  0.100            0.158  0.157  \n",
       "                  0.500            0.601  0.586  \n",
       "                  0.900            0.649  0.627  \n",
       "                  0.999            0.639  0.634  \n",
       "6       italiana  0.100            0.484  0.415  \n",
       "                  0.500            0.735  0.735  \n",
       "                  0.900            0.796  0.796  \n",
       "                  0.999            0.766  0.766  \n",
       "7       polonesa  0.100            0.365  0.387  \n",
       "                  0.500            0.683  0.697  \n",
       "                  0.900            0.740  0.754  \n",
       "                  0.999            0.742  0.748  \n",
       "8       polonesa  0.100            0.534  0.496  \n",
       "                  0.500            0.893  0.893  \n",
       "                  0.900            0.931  0.931  \n",
       "                  0.999            0.931  0.931  \n",
       "9       espanhola 0.100            0.200  0.257  \n",
       "                  0.500            0.604  0.599  \n",
       "                  0.900            0.703  0.701  \n",
       "                  0.999            0.689  0.700  \n",
       "10      espanhola 0.100            0.506  0.506  \n",
       "                  0.500            0.660  0.637  \n",
       "                  0.900            0.640  0.640  \n",
       "                  0.999            0.619  0.619  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCV.pivot_table(\n",
    "            index=['problem','language','PCA_componentes'],\n",
    "            columns=['sublinear_tf', 'ngram_range'],\n",
    "            values='mean_test_score'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Medida F1 para os parâmetros }\n",
      "\\begin{tabular}{lllrrrrrrrr}\n",
      "\\toprule\n",
      "   &   & sublinear\\_tf & \\multicolumn{4}{l}{False} & \\multicolumn{4}{l}{True} \\\\\n",
      "   &   & ngram\\_range & (2, 3) & (2, 4) & (2, 5) & (3, 5) & (2, 3) & (2, 4) & (2, 5) & (3, 5) \\\\\n",
      "problem & language & PCA\\_componentes &    &    &    &    &    &    &    &    \\\\\n",
      "\\midrule\n",
      "1  & inglesa & 0.100 &  0.094 &  0.093 &  0.088 &  0.089 &  0.077 &  0.082 &  0.099 &  0.103 \\\\\n",
      "   &   & 0.500 &  0.391 &  0.360 &  0.431 &  0.412 &  0.433 &  0.496 &  0.484 &  0.473 \\\\\n",
      "   &   & 0.900 &  0.526 &  0.560 &  0.566 &  0.553 &  0.600 &  0.619 &  0.637 &  0.582 \\\\\n",
      "   &   & 0.999 &  0.517 &  0.548 &  0.542 &  0.554 &  0.634 &  0.630 &  0.629 &  0.612 \\\\\n",
      "2  & inglesa & 0.100 &  0.371 &  0.333 &  0.266 &  0.295 &  0.410 &  0.394 &  0.363 &  0.363 \\\\\n",
      "   &   & 0.500 &  0.672 &  0.672 &  0.666 &  0.666 &  0.829 &  0.901 &  0.872 &  0.872 \\\\\n",
      "   &   & 0.900 &  0.741 &  0.789 &  0.685 &  0.618 &  0.901 &  0.874 &  0.874 &  0.874 \\\\\n",
      "   &   & 0.999 &  0.800 &  0.806 &  0.768 &  0.817 &  0.943 &  0.912 &  0.874 &  0.836 \\\\\n",
      "3  & francesa & 0.100 &  0.142 &  0.147 &  0.194 &  0.205 &  0.179 &  0.202 &  0.198 &  0.189 \\\\\n",
      "   &   & 0.500 &  0.435 &  0.449 &  0.506 &  0.517 &  0.470 &  0.488 &  0.509 &  0.552 \\\\\n",
      "   &   & 0.900 &  0.517 &  0.548 &  0.502 &  0.537 &  0.564 &  0.621 &  0.632 &  0.625 \\\\\n",
      "   &   & 0.999 &  0.525 &  0.575 &  0.570 &  0.570 &  0.581 &  0.661 &  0.644 &  0.651 \\\\\n",
      "4  & francesa & 0.100 &  0.269 &  0.207 &  0.225 &  0.282 &  0.202 &  0.129 &  0.148 &  0.190 \\\\\n",
      "   &   & 0.500 &  0.350 &  0.419 &  0.340 &  0.297 &  0.388 &  0.338 &  0.390 &  0.383 \\\\\n",
      "   &   & 0.900 &  0.549 &  0.544 &  0.570 &  0.570 &  0.537 &  0.613 &  0.584 &  0.570 \\\\\n",
      "   &   & 0.999 &  0.477 &  0.603 &  0.598 &  0.636 &  0.604 &  0.613 &  0.587 &  0.570 \\\\\n",
      "5  & italiana & 0.100 &  0.181 &  0.244 &  0.243 &  0.236 &  0.125 &  0.158 &  0.158 &  0.157 \\\\\n",
      "   &   & 0.500 &  0.521 &  0.562 &  0.547 &  0.529 &  0.552 &  0.597 &  0.601 &  0.586 \\\\\n",
      "   &   & 0.900 &  0.581 &  0.574 &  0.575 &  0.568 &  0.611 &  0.650 &  0.649 &  0.627 \\\\\n",
      "   &   & 0.999 &  0.572 &  0.579 &  0.572 &  0.566 &  0.631 &  0.650 &  0.639 &  0.634 \\\\\n",
      "6  & italiana & 0.100 &  0.509 &  0.520 &  0.634 &  0.600 &  0.468 &  0.484 &  0.484 &  0.415 \\\\\n",
      "   &   & 0.500 &  0.796 &  0.796 &  0.796 &  0.747 &  0.730 &  0.697 &  0.735 &  0.735 \\\\\n",
      "   &   & 0.900 &  0.796 &  0.834 &  0.806 &  0.806 &  0.796 &  0.796 &  0.796 &  0.796 \\\\\n",
      "   &   & 0.999 &  0.766 &  0.796 &  0.796 &  0.796 &  0.766 &  0.766 &  0.766 &  0.766 \\\\\n",
      "7  & polonesa & 0.100 &  0.292 &  0.363 &  0.325 &  0.378 &  0.357 &  0.388 &  0.365 &  0.387 \\\\\n",
      "   &   & 0.500 &  0.516 &  0.598 &  0.607 &  0.594 &  0.656 &  0.707 &  0.683 &  0.697 \\\\\n",
      "   &   & 0.900 &  0.578 &  0.617 &  0.659 &  0.671 &  0.670 &  0.717 &  0.740 &  0.754 \\\\\n",
      "   &   & 0.999 &  0.616 &  0.642 &  0.687 &  0.680 &  0.684 &  0.685 &  0.742 &  0.748 \\\\\n",
      "8  & polonesa & 0.100 &  0.615 &  0.514 &  0.449 &  0.449 &  0.430 &  0.481 &  0.534 &  0.496 \\\\\n",
      "   &   & 0.500 &  0.749 &  0.834 &  0.813 &  0.787 &  0.893 &  0.893 &  0.893 &  0.893 \\\\\n",
      "   &   & 0.900 &  0.867 &  0.905 &  0.874 &  0.874 &  0.893 &  0.893 &  0.931 &  0.931 \\\\\n",
      "   &   & 0.999 &  0.905 &  0.931 &  0.931 &  0.931 &  0.893 &  0.893 &  0.931 &  0.931 \\\\\n",
      "9  & espanhola & 0.100 &  0.177 &  0.186 &  0.234 &  0.247 &  0.156 &  0.188 &  0.200 &  0.257 \\\\\n",
      "   &   & 0.500 &  0.459 &  0.523 &  0.547 &  0.529 &  0.570 &  0.568 &  0.604 &  0.599 \\\\\n",
      "   &   & 0.900 &  0.516 &  0.530 &  0.538 &  0.558 &  0.673 &  0.709 &  0.703 &  0.701 \\\\\n",
      "   &   & 0.999 &  0.512 &  0.530 &  0.584 &  0.595 &  0.656 &  0.695 &  0.689 &  0.700 \\\\\n",
      "10 & espanhola & 0.100 &  0.389 &  0.314 &  0.341 &  0.447 &  0.388 &  0.420 &  0.506 &  0.506 \\\\\n",
      "   &   & 0.500 &  0.499 &  0.391 &  0.397 &  0.371 &  0.640 &  0.609 &  0.660 &  0.637 \\\\\n",
      "   &   & 0.900 &  0.556 &  0.486 &  0.497 &  0.545 &  0.595 &  0.595 &  0.640 &  0.640 \\\\\n",
      "   &   & 0.999 &  0.509 &  0.537 &  0.541 &  0.528 &  0.574 &  0.574 &  0.619 &  0.619 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\label{tab:modeloPalavra}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.precision = 3  \n",
    "print(u\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Medida F1 para os parâmetros }\")\n",
    "\n",
    "print(dfCV.pivot_table(\n",
    "        index=['problem','language','PCA_componentes'],\n",
    "        columns=['sublinear_tf', 'ngram_range'],\n",
    "        values='mean_test_score'\n",
    "    ).to_latex().replace(\"     \",\" \"))\n",
    "print (\"\\label{tab:modeloPalavra}\")\n",
    "print(r\"\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "scatter requires x column to be numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5a5f20ed2954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfCV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'it'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdfCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PCA_componentes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scatter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdfCV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'it'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdfCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PCA_componentes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scatter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   2675\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36mplot_frame\u001b[0;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                  **kwds)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[1;32m   1685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             plot_obj = klass(data, x=x, y=y, subplots=subplots, ax=ax,\n\u001b[0;32m-> 1687\u001b[0;31m                              kind=kind, **kwds)\n\u001b[0m\u001b[1;32m   1688\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m             raise ValueError(\"plot kind %r can only be used for data frames\"\n",
      "\u001b[0;32m/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, x, y, s, c, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;31m# the handling of this argument later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mScatterPlot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' requires x column to be numeric'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' requires y column to be numeric'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: scatter requires x column to be numeric"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dfCV[(dfCV.language=='it') & (dfCV.sublinear_tf==True)].plot(x='PCA_componentes',y='mean_test_score', kind='scatter')\n",
    "dfCV[(dfCV.language=='it')& (dfCV.sublinear_tf==False)].plot(x='PCA_componentes',y='mean_test_score', kind='scatter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
