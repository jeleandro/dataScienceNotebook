{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para o PAN - Atribuição Autoral - 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#python basic libs\n",
    "from __future__ import print_function\n",
    "\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "import os;\n",
    "from os.path import join as pathjoin;\n",
    "\n",
    "import re;\n",
    "import glob;\n",
    "import json;\n",
    "import codecs;\n",
    "from collections import defaultdict;\n",
    "import pprint;\n",
    "import warnings;\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "\n",
    "#data analysis libs\n",
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import seaborn as sn;\n",
    "import matplotlib.pyplot as plt;\n",
    "import random;\n",
    "\n",
    "#machine learning libs\n",
    "#feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#preprocessing and transformation\n",
    "from sklearn.preprocessing import normalize, MaxAbsScaler, MinMaxScaler;\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder;\n",
    "from sklearn.decomposition import PCA;\n",
    "from sklearn.metrics.pairwise import cosine_similarity;\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "#classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#model valuation\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darwin-17.5.0-x86_64-i386-64bit\n",
      "NumPy 1.14.2\n",
      "SciPy 1.0.1\n",
      "Scikit-Learn 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "print(\"NumPy\", np.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paths configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = '/Users/joseeleandrocustodio/Dropbox/mestrado/02 - Pesquisa/code';\n",
    "\n",
    "inputDir= pathjoin(baseDir,'pan18aa');\n",
    "outputDir= pathjoin(baseDir,'out',\"oficial\");\n",
    "if not os.path.exists(outputDir):\n",
    "    os.mkdir(outputDir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCollectionsOfProblems(path):\n",
    "    # Reading information about the collection\n",
    "    infocollection = path+os.sep+'collection-info.json'\n",
    "    with open(infocollection, 'r') as f:\n",
    "        problems  = [\n",
    "            {\n",
    "                'problem': attrib['problem-name'],\n",
    "                'language': attrib['language'],\n",
    "                'encoding': attrib['encoding'],\n",
    "            }\n",
    "            for attrib in json.load(f)\n",
    "            \n",
    "        ]\n",
    "    return problems;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readProblem(path, problem):\n",
    "    # Reading information about the problem\n",
    "    infoproblem = path+os.sep+problem+os.sep+'problem-info.json'\n",
    "    candidates = []\n",
    "    with open(infoproblem, 'r') as f:\n",
    "        fj = json.load(f)\n",
    "        unk_folder = fj['unknown-folder']\n",
    "        for attrib in fj['candidate-authors']:\n",
    "            candidates.append(attrib['author-name'])\n",
    "    return unk_folder, candidates;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path,label):\n",
    "    # Reads all text files located in the 'path' and assigns them to 'label' class\n",
    "    files = glob.glob(pathjoin(path,label,'*.txt'))\n",
    "    texts=[]\n",
    "    for i,v in enumerate(files):\n",
    "        f=codecs.open(v,'r',encoding='utf-8')\n",
    "        texts.append((f.read(),label, os.path.basename(v)))\n",
    "        f.close()\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = readCollectionsOfProblems(inputDir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index,problem in enumerate(problems):\n",
    "    unk_folder, candidates_folder = readProblem(inputDir, problem['problem']); \n",
    "    problem['candidates_folder_count'] = len(candidates_folder);\n",
    "    problem['candidates'] = [];\n",
    "    for candidate in candidates_folder:\n",
    "        problem['candidates'].extend(read_files(pathjoin(inputDir, problem['problem']),candidate));\n",
    "    \n",
    "    problem['unknown'] = read_files(pathjoin(inputDir, problem['problem']),unk_folder);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidates</th>\n",
       "      <th>candidates_folder_count</th>\n",
       "      <th>encoding</th>\n",
       "      <th>language</th>\n",
       "      <th>problem</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(graceful ones.\\n\\n\"One more,\" Marvelous said...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>en</td>\n",
       "      <td>problem00001</td>\n",
       "      <td>[(after all, his best friends. And what in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(a mission.\"\\n\\nJensen just raises an eyebrow...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>en</td>\n",
       "      <td>problem00002</td>\n",
       "      <td>[(“Potter was attractive,” Draco thought, sigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(qui l'avait tué mais tout était de la faute ...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>fr</td>\n",
       "      <td>problem00003</td>\n",
       "      <td>[(son réveil. Sa main pulse et Draco frotte l'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(. Le canapé est vide et lorsqu'il passe deva...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>fr</td>\n",
       "      <td>problem00004</td>\n",
       "      <td>[(abasourdie.\\n\\nTout d'abord, elle crut que s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(Eppure lui la mappa l’aveva stampata, dannaz...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>it</td>\n",
       "      <td>problem00005</td>\n",
       "      <td>[(– Oh. Cazzo.\\nSirius era così sconvolto che ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[(Yato ha trovato una lettera sul suo comodino...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>it</td>\n",
       "      <td>problem00006</td>\n",
       "      <td>[(così la tua vista, Moony?\\n– Cercavo di esse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[(zmienił zdanie. Niech się stworzonko pobawi....</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>pl</td>\n",
       "      <td>problem00007</td>\n",
       "      <td>[(dawniej pełna radości i ciepła, a teraz wiec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[(Słowem, które Sherlock najczęściej słyszał w...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>pl</td>\n",
       "      <td>problem00008</td>\n",
       "      <td>[(, uderzającego o żebra niczym dzwon- niemal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[(pero no lo ama como ama a Guignol –explicó e...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>sp</td>\n",
       "      <td>problem00009</td>\n",
       "      <td>[(–La nariz puntiaguda del elfo casi rozaba el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[(incapaz de señalar un momento exacto, un pun...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>sp</td>\n",
       "      <td>problem00010</td>\n",
       "      <td>[(tan parecidas hizo que su trasero latiese de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          candidates  candidates_folder_count  \\\n",
       "0  [(graceful ones.\\n\\n\"One more,\" Marvelous said...                       20   \n",
       "1  [(a mission.\"\\n\\nJensen just raises an eyebrow...                        5   \n",
       "2  [(qui l'avait tué mais tout était de la faute ...                       20   \n",
       "3  [(. Le canapé est vide et lorsqu'il passe deva...                        5   \n",
       "4  [(Eppure lui la mappa l’aveva stampata, dannaz...                       20   \n",
       "5  [(Yato ha trovato una lettera sul suo comodino...                        5   \n",
       "6  [(zmienił zdanie. Niech się stworzonko pobawi....                       20   \n",
       "7  [(Słowem, które Sherlock najczęściej słyszał w...                        5   \n",
       "8  [(pero no lo ama como ama a Guignol –explicó e...                       20   \n",
       "9  [(incapaz de señalar un momento exacto, un pun...                        5   \n",
       "\n",
       "  encoding language       problem  \\\n",
       "0    UTF-8       en  problem00001   \n",
       "1    UTF-8       en  problem00002   \n",
       "2    UTF-8       fr  problem00003   \n",
       "3    UTF-8       fr  problem00004   \n",
       "4    UTF-8       it  problem00005   \n",
       "5    UTF-8       it  problem00006   \n",
       "6    UTF-8       pl  problem00007   \n",
       "7    UTF-8       pl  problem00008   \n",
       "8    UTF-8       sp  problem00009   \n",
       "9    UTF-8       sp  problem00010   \n",
       "\n",
       "                                             unknown  \n",
       "0  [(after all, his best friends. And what in the...  \n",
       "1  [(“Potter was attractive,” Draco thought, sigh...  \n",
       "2  [(son réveil. Sa main pulse et Draco frotte l'...  \n",
       "3  [(abasourdie.\\n\\nTout d'abord, elle crut que s...  \n",
       "4  [(– Oh. Cazzo.\\nSirius era così sconvolto che ...  \n",
       "5  [(così la tua vista, Moony?\\n– Cercavo di esse...  \n",
       "6  [(dawniej pełna radości i ciepła, a teraz wiec...  \n",
       "7  [(, uderzającego o żebra niczym dzwon- niemal ...  \n",
       "8  [(–La nariz puntiaguda del elfo casi rozaba el...  \n",
       "9  [(tan parecidas hizo que su trasero latiese de...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************************************************************************\n",
    "\n",
    "def eval_measures(gt, pred):\n",
    "    \"\"\"Compute macro-averaged F1-scores, macro-averaged precision, \n",
    "    macro-averaged recall, and micro-averaged accuracy according the ad hoc\n",
    "    rules discussed at the top of this file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt : dict\n",
    "        Ground truth, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    pred : dict\n",
    "        Predicted attribution, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    Returns\n",
    "    -------\n",
    "    f1 : float\n",
    "        Macro-averaged F1-score\n",
    "    precision : float\n",
    "        Macro-averaged precision\n",
    "    recall : float\n",
    "        Macro-averaged recall\n",
    "    accuracy : float\n",
    "        Micro-averaged F1-score\n",
    "    \"\"\"\n",
    "\n",
    "    actual_authors = list(gt.values())\n",
    "    encoder = LabelEncoder().fit(['<UNK>'] + actual_authors)\n",
    "\n",
    "    text_ids, gold_authors, silver_authors = [], [], []\n",
    "    for text_id in sorted(gt):\n",
    "        text_ids.append(text_id)\n",
    "        gold_authors.append(gt[text_id])\n",
    "        try:\n",
    "            silver_authors.append(pred[text_id])\n",
    "        except KeyError:\n",
    "            # missing attributions get <UNK>:\n",
    "            silver_authors.append('<UNK>')\n",
    "\n",
    "    assert len(text_ids) == len(gold_authors)\n",
    "    assert len(text_ids) == len(silver_authors)\n",
    "\n",
    "    # replace non-existent silver authors with '<UNK>':\n",
    "    silver_authors = [a if a in encoder.classes_ else '<UNK>' \n",
    "                      for a in silver_authors]\n",
    "\n",
    "    gold_author_ints   = encoder.transform(gold_authors)\n",
    "    silver_author_ints = encoder.transform(silver_authors)\n",
    "\n",
    "    # get F1 for individual classes (and suppress warnings):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        f1 = f1_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels=list(set(gold_author_ints)),\n",
    "                  average='macro')\n",
    "        precision = precision_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels=list(set(gold_author_ints)),\n",
    "                  average='macro')\n",
    "        recall = recall_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels=list(set(gold_author_ints)),\n",
    "                  average='macro')\n",
    "        accuracy = accuracy_score(gold_author_ints,\n",
    "                  silver_author_ints)\n",
    "\n",
    "    return f1,precision,recall,accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth_file,predictions_file):\n",
    "    # Calculates evaluation measures for a single attribution problem\n",
    "    gt = {}\n",
    "    with open(ground_truth_file, 'r') as f:\n",
    "        for attrib in json.load(f)['ground_truth']:\n",
    "            gt[attrib['unknown-text']] = attrib['true-author']\n",
    "\n",
    "    pred = {}\n",
    "    with open(predictions_file, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            if attrib['unknown-text'] not in pred:\n",
    "                pred[attrib['unknown-text']] = attrib['predicted-author']\n",
    "    f1,precision,recall,accuracy =  eval_measures(gt,pred)\n",
    "    return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    \"\"\"Convert a sparse array into a dense array.\"\"\"\n",
    "\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runML(problem):\n",
    "    print (\"\\nProblem: %s,  language: %s, \" %(problem['problem'],problem['language']))\n",
    "    \n",
    "    train_docs, train_labels, _   = zip(*problem['candidates'])\n",
    "    problem['training_docs_size'] = len(train_docs);\n",
    "    test_docs, _, test_filename   = zip(*problem['unknown'])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect',   TfidfVectorizer(analyzer='word',\n",
    "                                   norm='l1',\n",
    "                                   max_df=1.0,\n",
    "                                   ngram_range=(1,3),\n",
    "                                   lowercase =True,\n",
    "                                   sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.9999)),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # uncommenting more parameters will give better exploring power but will\n",
    "    # increase processing time in a combinatorial way\n",
    "    parameters = {\n",
    "        'vect__min_df':(2,0.01,0.05,0.1)\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline,\n",
    "                               parameters,\n",
    "                               cv=5,\n",
    "                               scoring='f1_macro',\n",
    "                               n_jobs=-1,\n",
    "                               verbose=False\n",
    "                               )\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, train_labels)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    train_pred=grid_search.predict(train_docs);\n",
    "    test_pred=grid_search.predict(test_docs);\n",
    "    \n",
    "    \n",
    "    # Writing output file\n",
    "    out_data=[]\n",
    "    for i,v in enumerate(test_pred):\n",
    "        out_data.append({'unknown-text': test_filename[i],'predicted-author': v})\n",
    "    answerFile = pathjoin(outputDir,'answers-'+problem['problem']+'.json');\n",
    "    with open(answerFile, 'w') as f:\n",
    "        json.dump(out_data, f, indent=4)\n",
    "        #allProblems.extend(out_data)\n",
    "    \n",
    "    \n",
    "    #evaluation train\n",
    "    f1,precision,recall,accuracy=evaluate(\n",
    "                pathjoin(inputDir, problem['problem'], 'ground-truth.json'),\n",
    "                answerFile)\n",
    "    \n",
    "    return {\n",
    "                'problem-name'  :       problem['problem'],\n",
    "                \"language\"      :       problem['language'],\n",
    "                'AuthorCount'   :       len(set(train_labels)),\n",
    "                \"train_doc_size\":       len(train_docs),\n",
    "                \"train_caract_per_doc\": sum([len(l) for l in train_docs])/len(train_docs),\n",
    "                \"test_doc_size\" :       len(test_docs),\n",
    "                \"test_caract_per_doc\":  sum([len(l) for l in test_docs])/len(test_docs),\n",
    "                \n",
    "                'macro-f1'       : round(f1,3),\n",
    "                'macro-precision': round(precision,3),\n",
    "                'macro-recall'   : round(recall,3),\n",
    "                'micro-accuracy' : round(accuracy,3),\n",
    "                \n",
    "        }, grid_search.cv_results_, best_parameters;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examinando o parametro min_df isoladamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: problem00001,  language: en, \n",
      "Performing grid search...\n",
      "done in 39.641s\n",
      "Best score: 0.653\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00002,  language: en, \n",
      "Performing grid search...\n",
      "done in 12.632s\n",
      "Best score: 0.939\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00003,  language: fr, \n",
      "Performing grid search...\n",
      "done in 36.503s\n",
      "Best score: 0.686\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00004,  language: fr, \n",
      "Performing grid search...\n",
      "done in 12.361s\n",
      "Best score: 0.810\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00005,  language: it, \n",
      "Performing grid search...\n",
      "done in 37.516s\n",
      "Best score: 0.600\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00006,  language: it, \n",
      "Performing grid search...\n",
      "done in 12.988s\n",
      "Best score: 0.832\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00007,  language: pl, \n",
      "Performing grid search...\n",
      "done in 40.408s\n",
      "Best score: 0.712\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00008,  language: pl, \n",
      "Performing grid search...\n",
      "done in 11.931s\n",
      "Best score: 0.765\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.1\n",
      "\n",
      "Problem: problem00009,  language: sp, \n",
      "Performing grid search...\n",
      "done in 39.330s\n",
      "Best score: 0.829\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00010,  language: sp, \n",
      "Performing grid search...\n",
      "done in 12.505s\n",
      "Best score: 0.893\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n"
     ]
    }
   ],
   "source": [
    "result = [];\n",
    "cv_result = [];\n",
    "best_parameters = [];\n",
    "for problem in problems:\n",
    "    r, c, b = runML(problem);\n",
    "    result.append(r);\n",
    "    cv_result.append(c);\n",
    "    b['problem'] = problem['problem'];\n",
    "    best_parameters.append(b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>vect__min_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem00001</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem00002</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem00003</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem00004</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem00005</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem00006</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>problem00007</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>problem00008</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>problem00009</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>problem00010</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        problem  vect__min_df\n",
       "0  problem00001          2.00\n",
       "1  problem00002          0.01\n",
       "2  problem00003          2.00\n",
       "3  problem00004          0.01\n",
       "4  problem00005          2.00\n",
       "5  problem00006          0.01\n",
       "6  problem00007          2.00\n",
       "7  problem00008          0.10\n",
       "8  problem00009          2.00\n",
       "9  problem00010          2.00"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(best_parameters)[['problem','vect__min_df']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analisando os demais parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runML(problem):\n",
    "    print (\"\\nProblem: %s,  language: %s, \" %(problem['problem'],problem['language']))\n",
    "    \n",
    "    train_docs, train_labels, _   = zip(*problem['candidates'])\n",
    "    problem['training_docs_size'] = len(train_docs);\n",
    "    test_docs, _, test_filename   = zip(*problem['unknown'])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect',   TfidfVectorizer(analyzer='word',\n",
    "                                   norm='l1',\n",
    "                                   min_df=2,\n",
    "                                   max_df=1.0,\n",
    "                                   smooth_idf=True,\n",
    "                                   lowercase =True,\n",
    "                                   sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA()),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "    \n",
    "    # uncommenting more parameters will give better exploring power but will\n",
    "    # increase processing time in a combinatorial way\n",
    "    parameters = {\n",
    "        'vect__ngram_range':((1,1),(1,2),(1,3)),\n",
    "        'vect__sublinear_tf':(True, False),\n",
    "        'transf__n_components': (0.1,0.5,0.9,0.9999),\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline,\n",
    "                               parameters,\n",
    "                               cv=5,\n",
    "                               scoring='f1_macro',\n",
    "                               n_jobs=-1,\n",
    "                               verbose=False\n",
    "                               )\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, train_labels)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    train_pred=grid_search.predict(train_docs);\n",
    "    test_pred=grid_search.predict(test_docs);\n",
    "    \n",
    "    \n",
    "    # Writing output file\n",
    "    out_data=[]\n",
    "    for i,v in enumerate(test_pred):\n",
    "        out_data.append({'unknown-text': test_filename[i],'predicted-author': v})\n",
    "    answerFile = pathjoin(outputDir,'answers-'+problem['problem']+'.json');\n",
    "    with open(answerFile, 'w') as f:\n",
    "        json.dump(out_data, f, indent=4)\n",
    "        #allProblems.extend(out_data)\n",
    "    \n",
    "    \n",
    "    #evaluation train\n",
    "    f1,precision,recall,accuracy=evaluate(\n",
    "                pathjoin(inputDir, problem['problem'], 'ground-truth.json'),\n",
    "                answerFile)\n",
    "    \n",
    "    return {\n",
    "                'problem-name'  :       problem['problem'],\n",
    "                \"language\"      :       problem['language'],\n",
    "                'AuthorCount'   :       len(set(train_labels)),\n",
    "                \"train_doc_size\":       len(train_docs),\n",
    "                \"train_caract_per_doc\": sum([len(l) for l in train_docs])/len(train_docs),\n",
    "                \"test_doc_size\" :       len(test_docs),\n",
    "                \"test_caract_per_doc\":  sum([len(l) for l in test_docs])/len(test_docs),\n",
    "                \n",
    "                'macro-f1'       : round(f1,3),\n",
    "                'macro-precision': round(precision,3),\n",
    "                'macro-recall'   : round(recall,3),\n",
    "                'micro-accuracy' : round(accuracy,3),\n",
    "                \n",
    "        }, grid_search.cv_results_, best_parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: problem00001,  language: en, \n",
      "Performing grid search...\n",
      "done in 53.797s\n",
      "Best score: 0.655\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (1, 3)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00002,  language: en, \n",
      "Performing grid search...\n",
      "done in 13.164s\n",
      "Best score: 0.872\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00003,  language: fr, \n",
      "Performing grid search...\n",
      "done in 59.173s\n",
      "Best score: 0.696\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9999\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00004,  language: fr, \n",
      "Performing grid search...\n",
      "done in 12.435s\n",
      "Best score: 0.860\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9999\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00005,  language: it, \n",
      "Performing grid search...\n",
      "done in 57.244s\n",
      "Best score: 0.628\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9999\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00006,  language: it, \n",
      "Performing grid search...\n",
      "done in 12.116s\n",
      "Best score: 0.834\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00007,  language: pl, \n",
      "Performing grid search...\n",
      "done in 53.600s\n",
      "Best score: 0.717\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9999\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00008,  language: pl, \n",
      "Performing grid search...\n",
      "done in 12.262s\n",
      "Best score: 0.763\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00009,  language: sp, \n",
      "Performing grid search...\n",
      "done in 53.479s\n",
      "Best score: 0.832\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9999\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00010,  language: sp, \n",
      "Performing grid search...\n",
      "done in 12.518s\n",
      "Best score: 0.898\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__sublinear_tf: False\n"
     ]
    }
   ],
   "source": [
    "result = [];\n",
    "cv_result = [];\n",
    "best_parameters = [];\n",
    "for problem in problems:\n",
    "    r, c, b = runML(problem);\n",
    "    result.append(r);\n",
    "    cv_result.append(c);\n",
    "    b['problem'] = problem['problem'];\n",
    "    best_parameters.append(b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(result)[['problem-name',\n",
    "                     \"language\",\n",
    "                     'AuthorCount',\n",
    "                     \"train_doc_size\",\"train_caract_per_doc\",\n",
    "                     \"test_doc_size\", \"test_caract_per_doc\",\n",
    "                     'macro-f1','macro-precision','macro-recall' ,'micro-accuracy']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem-name</th>\n",
       "      <th>language</th>\n",
       "      <th>AuthorCount</th>\n",
       "      <th>train_doc_size</th>\n",
       "      <th>train_caract_per_doc</th>\n",
       "      <th>test_doc_size</th>\n",
       "      <th>test_caract_per_doc</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>macro-precision</th>\n",
       "      <th>macro-recall</th>\n",
       "      <th>micro-accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem00001</td>\n",
       "      <td>en</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4327</td>\n",
       "      <td>105</td>\n",
       "      <td>4370</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem00002</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4342</td>\n",
       "      <td>21</td>\n",
       "      <td>4296</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem00003</td>\n",
       "      <td>fr</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4492</td>\n",
       "      <td>49</td>\n",
       "      <td>4508</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem00004</td>\n",
       "      <td>fr</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4522</td>\n",
       "      <td>21</td>\n",
       "      <td>4532</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem00005</td>\n",
       "      <td>it</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4720</td>\n",
       "      <td>80</td>\n",
       "      <td>4787</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem00006</td>\n",
       "      <td>it</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4847</td>\n",
       "      <td>46</td>\n",
       "      <td>4765</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>problem00007</td>\n",
       "      <td>pl</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>5145</td>\n",
       "      <td>103</td>\n",
       "      <td>5200</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>problem00008</td>\n",
       "      <td>pl</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>5049</td>\n",
       "      <td>15</td>\n",
       "      <td>5214</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>problem00009</td>\n",
       "      <td>sp</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4794</td>\n",
       "      <td>117</td>\n",
       "      <td>4788</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>problem00010</td>\n",
       "      <td>sp</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4955</td>\n",
       "      <td>64</td>\n",
       "      <td>4827</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem-name language  AuthorCount  train_doc_size  train_caract_per_doc  \\\n",
       "0  problem00001       en           20             140                  4327   \n",
       "1  problem00002       en            5              35                  4342   \n",
       "2  problem00003       fr           20             140                  4492   \n",
       "3  problem00004       fr            5              35                  4522   \n",
       "4  problem00005       it           20             140                  4720   \n",
       "5  problem00006       it            5              35                  4847   \n",
       "6  problem00007       pl           20             140                  5145   \n",
       "7  problem00008       pl            5              35                  5049   \n",
       "8  problem00009       sp           20             140                  4794   \n",
       "9  problem00010       sp            5              35                  4955   \n",
       "\n",
       "   test_doc_size  test_caract_per_doc  macro-f1  macro-precision  \\\n",
       "0            105                 4370     0.435            0.453   \n",
       "1             21                 4296     0.527            0.517   \n",
       "2             49                 4508     0.541            0.597   \n",
       "3             21                 4532     0.573            0.657   \n",
       "4             80                 4787     0.571            0.553   \n",
       "5             46                 4765     0.553            0.563   \n",
       "6            103                 5200     0.424            0.421   \n",
       "7             15                 5214     0.788            0.850   \n",
       "8            117                 4788     0.691            0.690   \n",
       "9             64                 4827     0.613            0.715   \n",
       "\n",
       "   macro-recall  micro-accuracy  \n",
       "0         0.563           0.562  \n",
       "1         0.633           0.714  \n",
       "2         0.603           0.592  \n",
       "3         0.667           0.571  \n",
       "4         0.765           0.625  \n",
       "5         0.590           0.652  \n",
       "6         0.540           0.495  \n",
       "7         0.856           0.800  \n",
       "8         0.741           0.675  \n",
       "9         0.613           0.703  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rr}\n",
      "\\toprule\n",
      " index &  macro-f1 \\\\\n",
      "\\midrule\n",
      " 0 & 0.435 \\\\\n",
      " 1 & 0.527 \\\\\n",
      " 2 & 0.541 \\\\\n",
      " 3 & 0.573 \\\\\n",
      " 4 & 0.571 \\\\\n",
      " 5 & 0.553 \\\\\n",
      " 6 & 0.424 \\\\\n",
      " 7 & 0.788 \\\\\n",
      " 8 & 0.691 \\\\\n",
      " 9 & 0.613 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"macro-f1\"]].reset_index().to_latex(index=False).replace(\"     \",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       macro-f1\n",
       "count    10.000\n",
       "mean      0.572\n",
       "std       0.109\n",
       "min       0.424\n",
       "25%       0.530\n",
       "50%       0.562\n",
       "75%       0.603\n",
       "max       0.788"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)[['macro-f1']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages={\n",
    "    'en':'inglesa',\n",
    "    'sp':'espanhola',\n",
    "    'it':'italiana',\n",
    "    'pl':'polonesa',\n",
    "    'fr':'francesa'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv_result2 = [];\n",
    "dfCV = pd.DataFrame();\n",
    "for i, c in enumerate(cv_result):\n",
    "    temp = pd.DataFrame(c);\n",
    "    temp['problem'] = i+1;\n",
    "    temp['language'] = languages[problems[i]['language']]\n",
    "    dfCV = dfCV.append(temp);\n",
    "\n",
    "for p in ['param_transf__n_components',\n",
    "    'mean_test_score','std_test_score','mean_train_score',   \n",
    "    'split0_test_score','split0_train_score',\n",
    "    'split1_test_score','split1_train_score',\n",
    "    'split2_test_score','split2_train_score',\n",
    "    'split3_test_score','split3_train_score',\n",
    "    'split4_test_score','split4_train_score']:\n",
    "    dfCV[p]=dfCV[p].astype(np.float32);\n",
    "\n",
    "    \n",
    "dfCV =dfCV[[\n",
    "    'problem',\n",
    "    'language',\n",
    "    'rank_test_score',\n",
    "    'param_transf__n_components',\n",
    "    'param_vect__ngram_range',\n",
    "    'param_vect__sublinear_tf',\n",
    "    'mean_test_score',   \n",
    "    'std_test_score',\n",
    "    'mean_train_score',   \n",
    "\n",
    "    'split0_test_score','split0_train_score',\n",
    "    'split1_test_score','split1_train_score',\n",
    "    'split2_test_score','split2_train_score',\n",
    "    'split3_test_score','split3_train_score',\n",
    "    'split4_test_score','split4_train_score',\n",
    "\n",
    "    'mean_score_time',\n",
    "    'mean_fit_time',\n",
    "    'std_fit_time',\n",
    "    'std_score_time',\n",
    "    'std_train_score',\n",
    "]];\n",
    "\n",
    "dfCV.rename(columns={\n",
    "    'param_transf__n_components':'PCA_componentes',\n",
    "    'param_vect__ngram_range':'ngram_range',\n",
    "    'param_vect__sublinear_tf':'sublinear_tf',\n",
    "    'param_vect__smooth_idf':'smooth_idf'\n",
    "},inplace=True);\n",
    "\n",
    "#print('\\',\\n\\''.join(dfCV.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCV.to_csv('PANAA2018_WORD.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCV = pd.read_csv('PANAA2018_WORD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>language</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>PCA_componentes</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>sublinear_tf</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.203776</td>\n",
       "      <td>0.092235</td>\n",
       "      <td>0.657004</td>\n",
       "      <td>0.143810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636694</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.678485</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.621748</td>\n",
       "      <td>0.040520</td>\n",
       "      <td>0.331657</td>\n",
       "      <td>0.041032</td>\n",
       "      <td>0.011941</td>\n",
       "      <td>0.036499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>21</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.167551</td>\n",
       "      <td>0.068010</td>\n",
       "      <td>0.639273</td>\n",
       "      <td>0.131111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608891</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>0.642871</td>\n",
       "      <td>0.261667</td>\n",
       "      <td>0.614682</td>\n",
       "      <td>0.041589</td>\n",
       "      <td>0.299157</td>\n",
       "      <td>0.052452</td>\n",
       "      <td>0.015229</td>\n",
       "      <td>0.024817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>19</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.211712</td>\n",
       "      <td>0.085075</td>\n",
       "      <td>0.756681</td>\n",
       "      <td>0.156905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781303</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.822436</td>\n",
       "      <td>0.403333</td>\n",
       "      <td>0.725746</td>\n",
       "      <td>0.094264</td>\n",
       "      <td>1.351161</td>\n",
       "      <td>0.278847</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>0.071142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>22</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.146697</td>\n",
       "      <td>0.037068</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.162051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814397</td>\n",
       "      <td>0.141667</td>\n",
       "      <td>0.811590</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.799369</td>\n",
       "      <td>0.098744</td>\n",
       "      <td>1.086395</td>\n",
       "      <td>0.143992</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>0.018045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>24</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.124116</td>\n",
       "      <td>0.029220</td>\n",
       "      <td>0.802479</td>\n",
       "      <td>0.090595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825802</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.887415</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.790706</td>\n",
       "      <td>0.156859</td>\n",
       "      <td>1.930711</td>\n",
       "      <td>0.334623</td>\n",
       "      <td>0.065006</td>\n",
       "      <td>0.073724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem language  rank_test_score  PCA_componentes ngram_range  \\\n",
       "0        1  inglesa               20              0.1      (1, 1)   \n",
       "1        1  inglesa               21              0.1      (1, 1)   \n",
       "2        1  inglesa               19              0.1      (1, 2)   \n",
       "3        1  inglesa               22              0.1      (1, 2)   \n",
       "4        1  inglesa               24              0.1      (1, 3)   \n",
       "\n",
       "   sublinear_tf  mean_test_score  std_test_score  mean_train_score  \\\n",
       "0          True         0.203776        0.092235          0.657004   \n",
       "1         False         0.167551        0.068010          0.639273   \n",
       "2          True         0.211712        0.085075          0.756681   \n",
       "3         False         0.146697        0.037068          0.809955   \n",
       "4          True         0.124116        0.029220          0.802479   \n",
       "\n",
       "   split0_test_score       ...         split2_train_score  split3_test_score  \\\n",
       "0           0.143810       ...                   0.636694           0.033333   \n",
       "1           0.131111       ...                   0.608891           0.039286   \n",
       "2           0.156905       ...                   0.781303           0.133333   \n",
       "3           0.162051       ...                   0.814397           0.141667   \n",
       "4           0.090595       ...                   0.825802           0.106667   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  mean_score_time  \\\n",
       "0            0.678485           0.241667            0.621748         0.040520   \n",
       "1            0.642871           0.261667            0.614682         0.041589   \n",
       "2            0.822436           0.403333            0.725746         0.094264   \n",
       "3            0.811590           0.186667            0.799369         0.098744   \n",
       "4            0.887415           0.140000            0.790706         0.156859   \n",
       "\n",
       "   mean_fit_time  std_fit_time  std_score_time  std_train_score  \n",
       "0       0.331657      0.041032        0.011941         0.036499  \n",
       "1       0.299157      0.052452        0.015229         0.024817  \n",
       "2       1.351161      0.278847        0.033180         0.071142  \n",
       "3       1.086395      0.143992        0.043748         0.018045  \n",
       "4       1.930711      0.334623        0.065006         0.073724  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>language</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>sublinear_tf</th>\n",
       "      <th>PCA_componentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>0.081579</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872381</td>\n",
       "      <td>0.096572</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.153399</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.171825</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5</td>\n",
       "      <td>italiana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628016</td>\n",
       "      <td>0.085412</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6</td>\n",
       "      <td>italiana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.203038</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6</td>\n",
       "      <td>italiana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.169197</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>7</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717143</td>\n",
       "      <td>0.092005</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762857</td>\n",
       "      <td>0.160983</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762857</td>\n",
       "      <td>0.160983</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762857</td>\n",
       "      <td>0.160983</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.762857</td>\n",
       "      <td>0.160983</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>9</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831905</td>\n",
       "      <td>0.034577</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>10</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>0.169058</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>10</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>0.169058</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>10</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>0.169058</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     problem   language  rank_test_score  mean_test_score  std_test_score  \\\n",
       "16         1    inglesa                1         0.655068        0.081579   \n",
       "38         2    inglesa                1         0.872381        0.096572   \n",
       "68         3   francesa                1         0.696429        0.153399   \n",
       "90         4   francesa                1         0.860000        0.171825   \n",
       "116        5   italiana                1         0.628016        0.085412   \n",
       "128        6   italiana                1         0.834286        0.203038   \n",
       "132        6   italiana                1         0.834286        0.169197   \n",
       "164        7   polonesa                1         0.717143        0.092005   \n",
       "190        8   polonesa                1         0.762857        0.160983   \n",
       "184        8   polonesa                1         0.762857        0.160983   \n",
       "188        8   polonesa                1         0.762857        0.160983   \n",
       "182        8   polonesa                1         0.762857        0.160983   \n",
       "212        9  espanhola                1         0.831905        0.034577   \n",
       "237       10  espanhola                1         0.898095        0.169058   \n",
       "231       10  espanhola                1         0.898095        0.169058   \n",
       "225       10  espanhola                1         0.898095        0.169058   \n",
       "\n",
       "    ngram_range  sublinear_tf  PCA_componentes  \n",
       "16       (1, 3)          True           0.9000  \n",
       "38       (1, 2)          True           0.9000  \n",
       "68       (1, 2)          True           0.9999  \n",
       "90       (1, 1)          True           0.9999  \n",
       "116      (1, 2)          True           0.9999  \n",
       "128      (1, 2)          True           0.5000  \n",
       "132      (1, 1)          True           0.9000  \n",
       "164      (1, 2)          True           0.9999  \n",
       "190      (1, 3)          True           0.9999  \n",
       "184      (1, 3)          True           0.9000  \n",
       "188      (1, 2)          True           0.9999  \n",
       "182      (1, 2)          True           0.9000  \n",
       "212      (1, 2)          True           0.9999  \n",
       "237      (1, 2)         False           0.9999  \n",
       "231      (1, 2)         False           0.9000  \n",
       "225      (1, 2)         False           0.5000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dfCV[dfCV.rank_test_score == 1])[\n",
    "    ['problem',\n",
    "     'language',\n",
    "    'rank_test_score',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "    'ngram_range',\n",
    "    'sublinear_tf',\n",
    "    'PCA_componentes']\n",
    "].sort_values(by=[\n",
    "    'problem',\n",
    "    'mean_test_score',\n",
    "    'ngram_range',\n",
    "    'sublinear_tf',\n",
    "    'PCA_componentes'\n",
    "], ascending=[True, False,False,False,False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sublinear_tf</th>\n",
       "      <th colspan=\"3\" halign=\"left\">False</th>\n",
       "      <th colspan=\"3\" halign=\"left\">True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>(1, 1)</th>\n",
       "      <th>(1, 2)</th>\n",
       "      <th>(1, 3)</th>\n",
       "      <th>(1, 1)</th>\n",
       "      <th>(1, 2)</th>\n",
       "      <th>(1, 3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem</th>\n",
       "      <th>language</th>\n",
       "      <th>PCA_componentes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">inglesa</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.167551</td>\n",
       "      <td>0.146697</td>\n",
       "      <td>0.135759</td>\n",
       "      <td>0.203776</td>\n",
       "      <td>0.211712</td>\n",
       "      <td>0.124116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.422925</td>\n",
       "      <td>0.544512</td>\n",
       "      <td>0.539422</td>\n",
       "      <td>0.464116</td>\n",
       "      <td>0.552857</td>\n",
       "      <td>0.552687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.557222</td>\n",
       "      <td>0.629184</td>\n",
       "      <td>0.622449</td>\n",
       "      <td>0.594082</td>\n",
       "      <td>0.644048</td>\n",
       "      <td>0.655068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.589048</td>\n",
       "      <td>0.630714</td>\n",
       "      <td>0.612857</td>\n",
       "      <td>0.596576</td>\n",
       "      <td>0.629762</td>\n",
       "      <td>0.652619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">inglesa</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.465714</td>\n",
       "      <td>0.252653</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.442177</td>\n",
       "      <td>0.247891</td>\n",
       "      <td>0.240952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.777143</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.750748</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.851429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.716190</td>\n",
       "      <td>0.775238</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.872381</td>\n",
       "      <td>0.870476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.841905</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.832381</td>\n",
       "      <td>0.870476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">francesa</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.281667</td>\n",
       "      <td>0.192835</td>\n",
       "      <td>0.199059</td>\n",
       "      <td>0.280595</td>\n",
       "      <td>0.257018</td>\n",
       "      <td>0.222241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.527925</td>\n",
       "      <td>0.585340</td>\n",
       "      <td>0.499128</td>\n",
       "      <td>0.624830</td>\n",
       "      <td>0.608163</td>\n",
       "      <td>0.619558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.638810</td>\n",
       "      <td>0.643844</td>\n",
       "      <td>0.627483</td>\n",
       "      <td>0.637925</td>\n",
       "      <td>0.688163</td>\n",
       "      <td>0.668708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.625476</td>\n",
       "      <td>0.665952</td>\n",
       "      <td>0.675578</td>\n",
       "      <td>0.645068</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.686258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">francesa</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.376562</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.175238</td>\n",
       "      <td>0.242276</td>\n",
       "      <td>0.205714</td>\n",
       "      <td>0.210476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.770476</td>\n",
       "      <td>0.729524</td>\n",
       "      <td>0.696190</td>\n",
       "      <td>0.770476</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.694286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.800952</td>\n",
       "      <td>0.802857</td>\n",
       "      <td>0.711429</td>\n",
       "      <td>0.829524</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.736190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.800952</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.774286</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.764762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">italiana</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.163881</td>\n",
       "      <td>0.096068</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.174473</td>\n",
       "      <td>0.149643</td>\n",
       "      <td>0.123302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.434422</td>\n",
       "      <td>0.461848</td>\n",
       "      <td>0.466939</td>\n",
       "      <td>0.471020</td>\n",
       "      <td>0.532857</td>\n",
       "      <td>0.546440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.540612</td>\n",
       "      <td>0.594274</td>\n",
       "      <td>0.536190</td>\n",
       "      <td>0.559218</td>\n",
       "      <td>0.589581</td>\n",
       "      <td>0.589036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.555941</td>\n",
       "      <td>0.624342</td>\n",
       "      <td>0.595612</td>\n",
       "      <td>0.555816</td>\n",
       "      <td>0.628016</td>\n",
       "      <td>0.600374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">italiana</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.255329</td>\n",
       "      <td>0.232381</td>\n",
       "      <td>0.290159</td>\n",
       "      <td>0.193333</td>\n",
       "      <td>0.227619</td>\n",
       "      <td>0.311255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.796191</td>\n",
       "      <td>0.803810</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.824762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.744762</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>0.794286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.744762</td>\n",
       "      <td>0.744762</td>\n",
       "      <td>0.832381</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.775238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">7</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">polonesa</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.265329</td>\n",
       "      <td>0.205661</td>\n",
       "      <td>0.222120</td>\n",
       "      <td>0.337296</td>\n",
       "      <td>0.196746</td>\n",
       "      <td>0.210913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.617755</td>\n",
       "      <td>0.630374</td>\n",
       "      <td>0.595442</td>\n",
       "      <td>0.668163</td>\n",
       "      <td>0.684354</td>\n",
       "      <td>0.651973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.662041</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>0.703878</td>\n",
       "      <td>0.694762</td>\n",
       "      <td>0.704286</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.659524</td>\n",
       "      <td>0.687143</td>\n",
       "      <td>0.671735</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>0.717143</td>\n",
       "      <td>0.711905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">8</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">polonesa</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.306984</td>\n",
       "      <td>0.316190</td>\n",
       "      <td>0.291429</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.296327</td>\n",
       "      <td>0.265850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.608571</td>\n",
       "      <td>0.592381</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>0.731429</td>\n",
       "      <td>0.681905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.662857</td>\n",
       "      <td>0.727619</td>\n",
       "      <td>0.758095</td>\n",
       "      <td>0.702857</td>\n",
       "      <td>0.762857</td>\n",
       "      <td>0.762857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.689524</td>\n",
       "      <td>0.724762</td>\n",
       "      <td>0.724762</td>\n",
       "      <td>0.727619</td>\n",
       "      <td>0.762857</td>\n",
       "      <td>0.762857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">9</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">espanhola</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.197128</td>\n",
       "      <td>0.193777</td>\n",
       "      <td>0.191596</td>\n",
       "      <td>0.189256</td>\n",
       "      <td>0.215454</td>\n",
       "      <td>0.227528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.623163</td>\n",
       "      <td>0.684286</td>\n",
       "      <td>0.649864</td>\n",
       "      <td>0.710136</td>\n",
       "      <td>0.747687</td>\n",
       "      <td>0.752619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.741020</td>\n",
       "      <td>0.789286</td>\n",
       "      <td>0.784830</td>\n",
       "      <td>0.801191</td>\n",
       "      <td>0.807619</td>\n",
       "      <td>0.803571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.748333</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.790782</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.831905</td>\n",
       "      <td>0.829048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">espanhola</th>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.405541</td>\n",
       "      <td>0.292480</td>\n",
       "      <td>0.233795</td>\n",
       "      <td>0.347619</td>\n",
       "      <td>0.318095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>0.791429</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.862857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9000</th>\n",
       "      <td>0.784762</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9999</th>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.898095</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sublinear_tf                          False                         True   \\\n",
       "ngram_range                          (1, 1)    (1, 2)    (1, 3)    (1, 1)   \n",
       "problem language  PCA_componentes                                           \n",
       "1       inglesa   0.1000           0.167551  0.146697  0.135759  0.203776   \n",
       "                  0.5000           0.422925  0.544512  0.539422  0.464116   \n",
       "                  0.9000           0.557222  0.629184  0.622449  0.594082   \n",
       "                  0.9999           0.589048  0.630714  0.612857  0.596576   \n",
       "2       inglesa   0.1000           0.465714  0.252653  0.357778  0.442177   \n",
       "                  0.5000           0.777143  0.796191  0.750748  0.723810   \n",
       "                  0.9000           0.805714  0.716190  0.775238  0.843810   \n",
       "                  0.9999           0.843810  0.841905  0.813333  0.843810   \n",
       "3       francesa  0.1000           0.281667  0.192835  0.199059  0.280595   \n",
       "                  0.5000           0.527925  0.585340  0.499128  0.624830   \n",
       "                  0.9000           0.638810  0.643844  0.627483  0.637925   \n",
       "                  0.9999           0.625476  0.665952  0.675578  0.645068   \n",
       "4       francesa  0.1000           0.376562  0.206667  0.175238  0.242276   \n",
       "                  0.5000           0.770476  0.729524  0.696190  0.770476   \n",
       "                  0.9000           0.800952  0.802857  0.711429  0.829524   \n",
       "                  0.9999           0.800952  0.833333  0.774286  0.860000   \n",
       "5       italiana  0.1000           0.163881  0.096068  0.084731  0.174473   \n",
       "                  0.5000           0.434422  0.461848  0.466939  0.471020   \n",
       "                  0.9000           0.540612  0.594274  0.536190  0.559218   \n",
       "                  0.9999           0.555941  0.624342  0.595612  0.555816   \n",
       "6       italiana  0.1000           0.255329  0.232381  0.290159  0.193333   \n",
       "                  0.5000           0.746667  0.826667  0.796191  0.803810   \n",
       "                  0.9000           0.794286  0.744762  0.786667  0.834286   \n",
       "                  0.9999           0.765714  0.744762  0.744762  0.832381   \n",
       "7       polonesa  0.1000           0.265329  0.205661  0.222120  0.337296   \n",
       "                  0.5000           0.617755  0.630374  0.595442  0.668163   \n",
       "                  0.9000           0.662041  0.711905  0.703878  0.694762   \n",
       "                  0.9999           0.659524  0.687143  0.671735  0.678333   \n",
       "8       polonesa  0.1000           0.306984  0.316190  0.291429  0.314286   \n",
       "                  0.5000           0.651429  0.608571  0.592381  0.643810   \n",
       "                  0.9000           0.662857  0.727619  0.758095  0.702857   \n",
       "                  0.9999           0.689524  0.724762  0.724762  0.727619   \n",
       "9       espanhola 0.1000           0.197128  0.193777  0.191596  0.189256   \n",
       "                  0.5000           0.623163  0.684286  0.649864  0.710136   \n",
       "                  0.9000           0.741020  0.789286  0.784830  0.801191   \n",
       "                  0.9999           0.748333  0.821429  0.790782  0.791667   \n",
       "10      espanhola 0.1000           0.311111  0.405541  0.292480  0.233795   \n",
       "                  0.5000           0.708571  0.898095  0.791429  0.746667   \n",
       "                  0.9000           0.784762  0.898095  0.893333  0.813333   \n",
       "                  0.9999           0.813333  0.898095  0.893333  0.813333   \n",
       "\n",
       "sublinear_tf                                           \n",
       "ngram_range                          (1, 2)    (1, 3)  \n",
       "problem language  PCA_componentes                      \n",
       "1       inglesa   0.1000           0.211712  0.124116  \n",
       "                  0.5000           0.552857  0.552687  \n",
       "                  0.9000           0.644048  0.655068  \n",
       "                  0.9999           0.629762  0.652619  \n",
       "2       inglesa   0.1000           0.247891  0.240952  \n",
       "                  0.5000           0.857143  0.851429  \n",
       "                  0.9000           0.872381  0.870476  \n",
       "                  0.9999           0.832381  0.870476  \n",
       "3       francesa  0.1000           0.257018  0.222241  \n",
       "                  0.5000           0.608163  0.619558  \n",
       "                  0.9000           0.688163  0.668708  \n",
       "                  0.9999           0.696429  0.686258  \n",
       "4       francesa  0.1000           0.205714  0.210476  \n",
       "                  0.5000           0.695238  0.694286  \n",
       "                  0.9000           0.795238  0.736190  \n",
       "                  0.9999           0.795238  0.764762  \n",
       "5       italiana  0.1000           0.149643  0.123302  \n",
       "                  0.5000           0.532857  0.546440  \n",
       "                  0.9000           0.589581  0.589036  \n",
       "                  0.9999           0.628016  0.600374  \n",
       "6       italiana  0.1000           0.227619  0.311255  \n",
       "                  0.5000           0.834286  0.824762  \n",
       "                  0.9000           0.763810  0.794286  \n",
       "                  0.9999           0.794286  0.775238  \n",
       "7       polonesa  0.1000           0.196746  0.210913  \n",
       "                  0.5000           0.684354  0.651973  \n",
       "                  0.9000           0.704286  0.670000  \n",
       "                  0.9999           0.717143  0.711905  \n",
       "8       polonesa  0.1000           0.296327  0.265850  \n",
       "                  0.5000           0.731429  0.681905  \n",
       "                  0.9000           0.762857  0.762857  \n",
       "                  0.9999           0.762857  0.762857  \n",
       "9       espanhola 0.1000           0.215454  0.227528  \n",
       "                  0.5000           0.747687  0.752619  \n",
       "                  0.9000           0.807619  0.803571  \n",
       "                  0.9999           0.831905  0.829048  \n",
       "10      espanhola 0.1000           0.347619  0.318095  \n",
       "                  0.5000           0.893333  0.862857  \n",
       "                  0.9000           0.893333  0.893333  \n",
       "                  0.9999           0.893333  0.893333  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCV.pivot_table(\n",
    "            index=['problem','language','PCA_componentes'],\n",
    "            columns=['sublinear_tf', 'ngram_range'],\n",
    "            values='mean_test_score'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Medida F1 para os parâmetros }\n",
      "\\begin{tabular}{lllrrr}\n",
      "\\toprule\n",
      "   &   & ngram\\_range &  (1, 1) &  (1, 2) &  (1, 3) \\\\\n",
      "problem & language & sublinear\\_tf &     &     &     \\\\\n",
      "\\midrule\n",
      "1  & inglesa & False &   0.589 &   0.631 &   0.613 \\\\\n",
      "   &   & True  &   0.597 &   0.630 &   0.653 \\\\\n",
      "2  & inglesa & False &   0.844 &   0.842 &   0.813 \\\\\n",
      "   &   & True  &   0.844 &   0.832 &   0.870 \\\\\n",
      "3  & francesa & False &   0.625 &   0.666 &   0.676 \\\\\n",
      "   &   & True  &   0.645 &   0.696 &   0.686 \\\\\n",
      "4  & francesa & False &   0.801 &   0.833 &   0.774 \\\\\n",
      "   &   & True  &   0.860 &   0.795 &   0.765 \\\\\n",
      "5  & italiana & False &   0.556 &   0.624 &   0.596 \\\\\n",
      "   &   & True  &   0.556 &   0.628 &   0.600 \\\\\n",
      "6  & italiana & False &   0.766 &   0.745 &   0.745 \\\\\n",
      "   &   & True  &   0.832 &   0.794 &   0.775 \\\\\n",
      "7  & polonesa & False &   0.660 &   0.687 &   0.672 \\\\\n",
      "   &   & True  &   0.678 &   0.717 &   0.712 \\\\\n",
      "8  & polonesa & False &   0.690 &   0.725 &   0.725 \\\\\n",
      "   &   & True  &   0.728 &   0.763 &   0.763 \\\\\n",
      "9  & espanhola & False &   0.748 &   0.821 &   0.791 \\\\\n",
      "   &   & True  &   0.792 &   0.832 &   0.829 \\\\\n",
      "10 & espanhola & False &   0.813 &   0.898 &   0.893 \\\\\n",
      "   &   & True  &   0.813 &   0.893 &   0.893 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\label{tab:modeloPalavra}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.precision = 3  \n",
    "print(u\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Medida F1 para os parâmetros }\")\n",
    "\n",
    "print(dfCV[dfCV.PCA_componentes == 0.9999].pivot_table(\n",
    "        index=['problem','language','sublinear_tf'],\n",
    "        columns=['ngram_range'],\n",
    "        values='mean_test_score'\n",
    "    ).to_latex().replace(\"     \",\" \"))\n",
    "print (\"\\label{tab:modeloPalavra}\")\n",
    "print(r\"\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCV =  dfCV[['problem', u'param_transf__n_components', u'param_vect__sublinear_tf', u'mean_test_score','rank_test_score']]\n",
    "\n",
    "    \n",
    "dfCV = dfCV[dfCV.rank_test_score == 1]\n",
    "dfCV.sort_values(by=['problem','mean_test_score','param_transf__n_components'], ascending=[True, False,False])\n",
    "dfCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result)\\\n",
    "    .sort_values(by=['language','problem-name'])[['language','problem-name','macro-f1']]\\\n",
    "    .plot(kind='bar', x=['language','problem-name'], legend=True, figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.param_transf__n_components = df.param_transf__n_components.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(            x='param_transf__n_components',\n",
    "            y='mean_test_score',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(cv_result[9])\n",
    "fig, ax = plt.subplots()\n",
    "colors = ['red','green', 'blue','pink'];\n",
    "i =0;\n",
    "for key, grp in df.groupby(['param_vect__sublinear_tf','param_vect__norm']):\n",
    "    ax = grp.plot(ylim=(0,1.0), xlim=(0,1.0),\n",
    "            ax=ax,\n",
    "            kind='line',\n",
    "            x='param_transf__n_components',\n",
    "            y='mean_test_score',\n",
    "            c = colors[i],\n",
    "            \n",
    "            label=key,\n",
    "            figsize=(10,10)\n",
    "    )\n",
    "    i=i+1;\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='param_transf__n_components', y='mean_test_score', ylim=(0,1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/>\n",
    "\n",
    "#  Abordagem desafiante 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramSplitter(object):\n",
    "    def __init__(self, text, ngram=(3,3), vocabulary=None):\n",
    "        self.text = text\n",
    "        self.ngram_min = ngram[0]\n",
    "        self.ngram_max = ngram[1];\n",
    "        self.vocabulary = vocabulary;\n",
    "    \n",
    "    def text2ngrams(self,text):\n",
    "        vect = [\n",
    "            text[t:t+j]\n",
    "                for t in xrange(len(text)-self.ngram_max+1)\n",
    "                for j in xrange(self.ngram_min, self.ngram_max+1)\n",
    "        ]\n",
    "        \n",
    "        if self.vocabulary is not None:\n",
    "            return [word for word in vect if word in self.vocabulary];\n",
    "        else:\n",
    "            return [word for word in vect if word]\n",
    " \n",
    "    def __iter__(self):\n",
    "        if isinstance(self.text,list):\n",
    "            for s in self.text:\n",
    "                yield self.text2ngrams(s);\n",
    "        elif isinstance(self.text,str) or isinstance(self.text,unicode):\n",
    "            yield self.text2ngrams(self.text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"A classifier that uses classes embeddings to classify instances\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            ngram = (3,4),\n",
    "            analyzer = 'char',\n",
    "            min_df = 0.3,\n",
    "            max_df = 1.0,\n",
    "        \n",
    "            min_count =2,\n",
    "            embeddingSize =750,\n",
    "            window=10,\n",
    "            algorithm = 0,\n",
    "            iter =10\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Called when initializing the classifier\n",
    "        \"\"\"\n",
    "        self.algorithm     = algorithm\n",
    "        self.min_count     = min_count\n",
    "        self.embeddingSize = embeddingSize\n",
    "        self.window        = window\n",
    "        self.iter          = iter\n",
    "        self.analyzer      = analyzer\n",
    "        self.vocabulary_   = {}\n",
    "        self.ngram         = ngram\n",
    "        self.min_df        = min_df\n",
    "        self.max_df        = max_df\n",
    "\n",
    "    def _buildVectorModel(self, document):\n",
    "        sentenseGenerator = NgramSplitter(document,self.ngram, self.vocabulary_);\n",
    "        \n",
    "        model = Word2Vec(\n",
    "            sentenseGenerator,\n",
    "            sg       = self.algorithm,\n",
    "            iter     = self.iter,        \n",
    "            min_count= self.min_count,\n",
    "            window   = self.window,\n",
    "            size     = self.embeddingSize,\n",
    "            seed=0\n",
    "        );\n",
    "        return model.wv;\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Sumarize one text per labels and transform the text into word vectors\n",
    "        \"\"\"\n",
    "        \n",
    "        #creating author profile\n",
    "        profile = defaultdict(unicode);\n",
    "        for text, label in zip(X,y):\n",
    "            profile[label]+=text;\n",
    "            \n",
    "        #build a global vocaculary / Using count vectorizer to create a fixed vocabulary\n",
    "        vectorizer = CountVectorizer(\n",
    "                analyzer=self.analyzer,\n",
    "                ngram_range=self.ngram,\n",
    "                min_df=self.min_df,\n",
    "                max_df=self.max_df,\n",
    "                lowercase=False\n",
    "        )\n",
    "        vectorizer.fit(X);\n",
    "        self.vocabulary_ = vectorizer.vocabulary_\n",
    "        \n",
    "        # profile vector represent each author in the embedding space\n",
    "        self.profileVectors_ = {y: self._buildVectorModel(profile[y]) for y in y};\n",
    "\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _minmax(self, a):\n",
    "        a = (a - a.min())/(a.max() - a.min());\n",
    "        return a;\n",
    "        \n",
    "    def _simpleCosine(self,a, b):\n",
    "        '''\n",
    "        calculates cosine between array a and b.\n",
    "        This function is used because sklearn similiraty function compares all elements vs all elements\n",
    "        what will not be used. So this function becames handy.\n",
    "        '''\n",
    "        a = a / np.sqrt(np.sum(a **2));\n",
    "        b = b / np.sqrt(np.sum(b **2));\n",
    "        cos = np.sum(np.array(a) * np.array(b));\n",
    "        return cos;\n",
    "    \n",
    "    def _KLD(self,p, q):\n",
    "        p = self._minmax(p); p = p/p.sum();\n",
    "        q = self._minmax(q); q = q/q.sum();\n",
    "        \n",
    "        cond = ((q != 0)&(p != 0));\n",
    "        k1 = np.sum(np.where(cond, p * np.log(p / q), 0));\n",
    "        return k1;\n",
    "    \n",
    "    def _manhattan(self,p, q):\n",
    "        p = self._minmax(p); p = p/p.sum();\n",
    "        q = self._minmax(q); q = q/q.sum();\n",
    "        return np.mean(np.abs(p-q));\n",
    "    \n",
    "    \n",
    "    def _guassian(self, C,D):\n",
    "        cond = C-D !=0;\n",
    "        bc = np.where(cond,(C-D+1)**2/(2*np.maximum(C,D+1)),1);\n",
    "        return np.sum(-np.log(bc));\n",
    "\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        # counts number of values bigger than mean\n",
    "        return(sum(self.predict(X)))\n",
    "    \n",
    "    def _softMax(self,a):\n",
    "        a = self._minmax(a);\n",
    "        a = np.exp(a)/np.sum(np.exp(a))\n",
    "        return a;\n",
    "    \n",
    "    def _predict1Doc(self, docVect):\n",
    "        vocabDoc = set(docVect.vocab.keys());\n",
    "    \n",
    "        metrics = [];\n",
    "        \n",
    "        def c(aa,bb, funct):\n",
    "            voc = set(aa.vocab.keys()) & set(bb.vocab.keys())\n",
    "            f = np.array([\n",
    "                funct(aa[v], bb[v])\n",
    "                for v in voc\n",
    "            ]);\n",
    "            f = np.sum(f)\n",
    "            return f;\n",
    "    \n",
    "        for label in self.profileVectors_:\n",
    "            labelVocab = set(self.profileVectors_[label].vocab.keys());\n",
    "            intersect  = vocabDoc & labelVocab;\n",
    "            union      = len(vocabDoc | labelVocab);\n",
    "            jaccard    = 1.0*len(intersect) / union;\n",
    "            \n",
    "            metrics.append({\n",
    "                'label'       : label,\n",
    "                'jaccard'     : jaccard,\n",
    "                'lenIntersect': len(intersect),\n",
    "                'lenUnion'    : union,\n",
    "                'lenMax'      : max(len(labelVocab), len(vocabDoc)),\n",
    "                'similarity'  : c(docVect, self.profileVectors_[label], self._simpleCosine),\n",
    "                'KLD'         : c(docVect, self.profileVectors_[label], self._KLD),\n",
    "                'manhattan'   : c(docVect, self.profileVectors_[label], self._manhattan),\n",
    "                'guassian'    : c(docVect, self.profileVectors_[label], self._guassian),\n",
    "                \n",
    "            })\n",
    "        #softmax norm\n",
    "        similarity = self._softMax(np.array([c['similarity'] for c in metrics ]));\n",
    "        guassian   = self._softMax(np.array([c['guassian'] for c in metrics ]));\n",
    "        manhattan  = self._softMax(np.array([c['manhattan'] for c in metrics ]));\n",
    "    \n",
    "        #appending normalized sum of distance\n",
    "        for i,c in enumerate(metrics):\n",
    "            c.update({\n",
    "                'similarityNorm': similarity[i],\n",
    "                'guassianNorm': guassian[i],\n",
    "                'manhattanNorm': manhattan[i]\n",
    "            })\n",
    "    \n",
    "        return metrics;\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"profileVectors_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "            \n",
    "        docVectors    = [self._buildVectorModel(x) for x in X];\n",
    "        self.metrics_ = [self._predict1Doc(v)      for v in docVectors];\n",
    "        \n",
    "        result = [];\n",
    "        for r in self.metrics_:\n",
    "            best = r[0];\n",
    "            best['bestMatch'] = True;\n",
    "            for rr in r:\n",
    "                if rr != best:\n",
    "                    rr['bestMatch'] = False;\n",
    "                if rr['similarityNorm'] > best['similarityNorm'] :\n",
    "                    best['bestMatch'] = False;\n",
    "                    best = rr;\n",
    "                    best['bestMatch'] = True;\n",
    "            result.append(best);\n",
    "            \n",
    "        self.predited_ = result;\n",
    "\n",
    "        return([r['label'] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = problems[8];\n",
    "print (\"Problem: %s,  language: %s, \" %(problem['problem'],problem['language']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2VecClassifier();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs, train_labels,_ = zip(*problem['candidates']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_docs,train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPred = model.predict(train_docs);\n",
    "trainMetrics = model.metrics_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(zip(train_labels,trainPred), columns=['label','pred'])\n",
    "df.label = df.label.apply(lambda x: int(re.sub(r'\\D','',x)));\n",
    "df.pred = df.pred.apply(lambda x: int(re.sub(r'\\D','',x)));\n",
    "df.plot.scatter(x='label',y='pred');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m  = trainMetrics\n",
    "df = pd.DataFrame([item for s in m for item in s])\n",
    "df['doc']      = [i               for i,s in enumerate(m) for item in s]\n",
    "df['solution'] = [train_labels[i] for i,s in enumerate(m) for item in s]\n",
    "df.sort_values(by=['doc','similarityNorm', 'manhattan'], ascending=[True,False,True], inplace=True)\n",
    "df['distance'] = [i for i in range(len(set(train_labels)))]* len(trainMetrics)\n",
    "df[df.doc == 55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.bestMatch].copy();\n",
    "df2['correct'] = df2.apply(lambda x: x['label'] == x['solution'], axis=1)\n",
    "df2[['correct','doc']].groupby(by='correct').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df[df.bestMatch].copy();\n",
    "df2['correct'] = df2.apply(lambda x: x['label'] == x['solution'], axis=1)\n",
    "df2[['correct','doc']].groupby(by='correct').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.solution == df.label].plot.scatter(x='distance', y='manhattanNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='distance', y='guassianNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='distance', y='similarityNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='manhattanNorm', y='guassianNorm', c='distance',colormap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from baseline\n",
    "gt = {}\n",
    "with open(pathjoin(inputDir, problem['problem'], 'ground-truth.json'), 'r') as f:\n",
    "    for attrib in json.load(f)['ground_truth']:\n",
    "        gt[attrib['unknown-text']] = attrib['true-author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs, _, test_filename = zip(*problem['unknown'])\n",
    "test_labels = [gt[v] for v in test_filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testPred = model.predict(test_docs);\n",
    "testMetrics = model.metrics_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m  = testMetrics\n",
    "df = pd.DataFrame([item for s in m for item in s])\n",
    "df['doc']      = [i               for i,s in enumerate(m) for item in s]\n",
    "df['solution'] = [train_labels[i] for i,s in enumerate(m) for item in s]\n",
    "df.sort_values(by=['doc','similarityNorm', 'KLD'], ascending=[True,False,True], inplace=True)\n",
    "df['distance'] = [i for i in range(len(set(train_labels)))]* len(testMetrics)\n",
    "df[df.doc == 55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,precision,recall,accuracy =  eval_measures(gt,{k: v for k,v in zip(test_filename, testPred)  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{\n",
    "                'macro-f1'       : round(f1,3),\n",
    "                'macro-precision': round(precision,3),\n",
    "                'macro-recall'   : round(recall,3),\n",
    "                'micro-accuracy' : round(accuracy,3)\n",
    "             }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.bestMatch].copy();\n",
    "df2['correct'] = df2.apply(lambda x: x['label'] == x['solution'], axis=1)\n",
    "df2[['correct','doc']].groupby(by='correct').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.solution == df.label].plot.scatter(x='distance', y='guassianNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='distance', y='manhattanNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='distance', y='similarityNorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.solution == df.label]\\\n",
    "    .plot\\\n",
    "    .scatter(\n",
    "        x='guassianNorm',\n",
    "        y='similarityNorm',\n",
    "        c='distance',\n",
    "        colormap='Reds',\n",
    "        figsize=(20,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
