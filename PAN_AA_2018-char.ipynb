{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook para o PAN - Atribuição Autoral - 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#python basic libs\n",
    "from __future__ import print_function\n",
    "\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "import os;\n",
    "from os.path import join as pathjoin;\n",
    "\n",
    "import re;\n",
    "import glob;\n",
    "import json;\n",
    "import codecs;\n",
    "from collections import defaultdict;\n",
    "import pprint;\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "\n",
    "#data analysis libs\n",
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import matplotlib.pyplot as plt;\n",
    "import random;\n",
    "\n",
    "#machine learning libs\n",
    "#feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#preprocessing and transformation\n",
    "from sklearn.preprocessing import normalize, MaxAbsScaler, MinMaxScaler;\n",
    "from sklearn.preprocessing import LabelBinarizer;\n",
    "from sklearn.decomposition import PCA;\n",
    "from sklearn.metrics.pairwise import cosine_similarity;\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "#classifiers\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFE,SelectFpr,SelectPercentile, chi2;\n",
    "\n",
    "#\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#model valuation\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns;\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darwin-17.5.0-x86_64-i386-64bit\n",
      "NumPy 1.14.2\n",
      "SciPy 1.0.1\n",
      "Scikit-Learn 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "print(\"NumPy\", np.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paths configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = '/Users/joseeleandrocustodio/Dropbox/mestrado/02 - Pesquisa/code';\n",
    "\n",
    "inputDir= pathjoin(baseDir,'pan18aa');\n",
    "outputDir= pathjoin(baseDir,'out',\"oficial\");\n",
    "if not os.path.exists(outputDir):\n",
    "    os.mkdir(outputDir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCollectionsOfProblems(path):\n",
    "    # Reading information about the collection\n",
    "    infocollection = path+os.sep+'collection-info.json'\n",
    "    with open(infocollection, 'r') as f:\n",
    "        problems  = [\n",
    "            {\n",
    "                'problem': attrib['problem-name'],\n",
    "                'language': attrib['language'],\n",
    "                'encoding': attrib['encoding'],\n",
    "            }\n",
    "            for attrib in json.load(f)\n",
    "            \n",
    "        ]\n",
    "    return problems;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = readCollectionsOfProblems(inputDir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': u'UTF-8', 'language': u'en', 'problem': u'problem00001'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readProblem(path, problem):\n",
    "    # Reading information about the problem\n",
    "    infoproblem = path+os.sep+problem+os.sep+'problem-info.json'\n",
    "    candidates = []\n",
    "    with open(infoproblem, 'r') as f:\n",
    "        fj = json.load(f)\n",
    "        unk_folder = fj['unknown-folder']\n",
    "        for attrib in fj['candidate-authors']:\n",
    "            candidates.append(attrib['author-name'])\n",
    "    return unk_folder, candidates;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path,label):\n",
    "    # Reads all text files located in the 'path' and assigns them to 'label' class\n",
    "    files = glob.glob(pathjoin(path,label,'*.txt'))\n",
    "    texts=[]\n",
    "    for i,v in enumerate(files):\n",
    "        f=codecs.open(v,'r',encoding='utf-8')\n",
    "        texts.append((f.read(),label, os.path.basename(v)))\n",
    "        f.close()\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index,problem in enumerate(problems):\n",
    "    unk_folder, candidates_folder = readProblem(inputDir, problem['problem']); \n",
    "    problem['candidates_folder_count'] = len(candidates_folder);\n",
    "    problem['candidates'] = [];\n",
    "    for candidate in candidates_folder:\n",
    "        problem['candidates'].extend(read_files(pathjoin(inputDir, problem['problem']),candidate));\n",
    "    \n",
    "    problem['unknown'] = read_files(pathjoin(inputDir, problem['problem']),unk_folder);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidates</th>\n",
       "      <th>candidates_folder_count</th>\n",
       "      <th>encoding</th>\n",
       "      <th>language</th>\n",
       "      <th>problem</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(graceful ones.\\n\\n\"One more,\" Marvelous said...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>en</td>\n",
       "      <td>problem00001</td>\n",
       "      <td>[(after all, his best friends. And what in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(a mission.\"\\n\\nJensen just raises an eyebrow...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>en</td>\n",
       "      <td>problem00002</td>\n",
       "      <td>[(“Potter was attractive,” Draco thought, sigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(qui l'avait tué mais tout était de la faute ...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>fr</td>\n",
       "      <td>problem00003</td>\n",
       "      <td>[(son réveil. Sa main pulse et Draco frotte l'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(. Le canapé est vide et lorsqu'il passe deva...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>fr</td>\n",
       "      <td>problem00004</td>\n",
       "      <td>[(abasourdie.\\n\\nTout d'abord, elle crut que s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(Eppure lui la mappa l’aveva stampata, dannaz...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>it</td>\n",
       "      <td>problem00005</td>\n",
       "      <td>[(– Oh. Cazzo.\\nSirius era così sconvolto che ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[(Yato ha trovato una lettera sul suo comodino...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>it</td>\n",
       "      <td>problem00006</td>\n",
       "      <td>[(così la tua vista, Moony?\\n– Cercavo di esse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[(zmienił zdanie. Niech się stworzonko pobawi....</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>pl</td>\n",
       "      <td>problem00007</td>\n",
       "      <td>[(dawniej pełna radości i ciepła, a teraz wiec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[(Słowem, które Sherlock najczęściej słyszał w...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>pl</td>\n",
       "      <td>problem00008</td>\n",
       "      <td>[(, uderzającego o żebra niczym dzwon- niemal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[(pero no lo ama como ama a Guignol –explicó e...</td>\n",
       "      <td>20</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>sp</td>\n",
       "      <td>problem00009</td>\n",
       "      <td>[(–La nariz puntiaguda del elfo casi rozaba el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[(incapaz de señalar un momento exacto, un pun...</td>\n",
       "      <td>5</td>\n",
       "      <td>UTF-8</td>\n",
       "      <td>sp</td>\n",
       "      <td>problem00010</td>\n",
       "      <td>[(tan parecidas hizo que su trasero latiese de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          candidates  candidates_folder_count  \\\n",
       "0  [(graceful ones.\\n\\n\"One more,\" Marvelous said...                       20   \n",
       "1  [(a mission.\"\\n\\nJensen just raises an eyebrow...                        5   \n",
       "2  [(qui l'avait tué mais tout était de la faute ...                       20   \n",
       "3  [(. Le canapé est vide et lorsqu'il passe deva...                        5   \n",
       "4  [(Eppure lui la mappa l’aveva stampata, dannaz...                       20   \n",
       "5  [(Yato ha trovato una lettera sul suo comodino...                        5   \n",
       "6  [(zmienił zdanie. Niech się stworzonko pobawi....                       20   \n",
       "7  [(Słowem, które Sherlock najczęściej słyszał w...                        5   \n",
       "8  [(pero no lo ama como ama a Guignol –explicó e...                       20   \n",
       "9  [(incapaz de señalar un momento exacto, un pun...                        5   \n",
       "\n",
       "  encoding language       problem  \\\n",
       "0    UTF-8       en  problem00001   \n",
       "1    UTF-8       en  problem00002   \n",
       "2    UTF-8       fr  problem00003   \n",
       "3    UTF-8       fr  problem00004   \n",
       "4    UTF-8       it  problem00005   \n",
       "5    UTF-8       it  problem00006   \n",
       "6    UTF-8       pl  problem00007   \n",
       "7    UTF-8       pl  problem00008   \n",
       "8    UTF-8       sp  problem00009   \n",
       "9    UTF-8       sp  problem00010   \n",
       "\n",
       "                                             unknown  \n",
       "0  [(after all, his best friends. And what in the...  \n",
       "1  [(“Potter was attractive,” Draco thought, sigh...  \n",
       "2  [(son réveil. Sa main pulse et Draco frotte l'...  \n",
       "3  [(abasourdie.\\n\\nTout d'abord, elle crut que s...  \n",
       "4  [(– Oh. Cazzo.\\nSirius era così sconvolto che ...  \n",
       "5  [(così la tua vista, Moony?\\n– Cercavo di esse...  \n",
       "6  [(dawniej pełna radości i ciepła, a teraz wiec...  \n",
       "7  [(, uderzającego o żebra niczym dzwon- niemal ...  \n",
       "8  [(–La nariz puntiaguda del elfo casi rozaba el...  \n",
       "9  [(tan parecidas hizo que su trasero latiese de...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************************************************************************\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def eval_measures(gt, pred):\n",
    "    \"\"\"Compute macro-averaged F1-scores, macro-averaged precision, \n",
    "    macro-averaged recall, and micro-averaged accuracy according the ad hoc\n",
    "    rules discussed at the top of this file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    gt : dict\n",
    "        Ground truth, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    pred : dict\n",
    "        Predicted attribution, where keys indicate text file names\n",
    "        (e.g. `unknown00002.txt`), and values represent\n",
    "        author labels (e.g. `candidate00003`)\n",
    "    Returns\n",
    "    -------\n",
    "    f1 : float\n",
    "        Macro-averaged F1-score\n",
    "    precision : float\n",
    "        Macro-averaged precision\n",
    "    recall : float\n",
    "        Macro-averaged recall\n",
    "    accuracy : float\n",
    "        Micro-averaged F1-score\n",
    "    \"\"\"\n",
    "\n",
    "    actual_authors = list(gt.values())\n",
    "    encoder = LabelEncoder().fit(['<UNK>'] + actual_authors)\n",
    "\n",
    "    text_ids, gold_authors, silver_authors = [], [], []\n",
    "    for text_id in sorted(gt):\n",
    "        text_ids.append(text_id)\n",
    "        gold_authors.append(gt[text_id])\n",
    "        try:\n",
    "            silver_authors.append(pred[text_id])\n",
    "        except KeyError:\n",
    "            # missing attributions get <UNK>:\n",
    "            silver_authors.append('<UNK>')\n",
    "\n",
    "    assert len(text_ids) == len(gold_authors)\n",
    "    assert len(text_ids) == len(silver_authors)\n",
    "\n",
    "    # replace non-existent silver authors with '<UNK>':\n",
    "    silver_authors = [a if a in encoder.classes_ else '<UNK>' \n",
    "                      for a in silver_authors]\n",
    "\n",
    "    gold_author_ints   = encoder.transform(gold_authors)\n",
    "    silver_author_ints = encoder.transform(silver_authors)\n",
    "\n",
    "    # get F1 for individual classes (and suppress warnings):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        f1 = f1_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels=list(set(gold_author_ints)),\n",
    "                  average='macro')\n",
    "        precision = precision_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels=list(set(gold_author_ints)),\n",
    "                  average='macro')\n",
    "        recall = recall_score(gold_author_ints,\n",
    "                  silver_author_ints,\n",
    "                  labels=list(set(gold_author_ints)),\n",
    "                  average='macro')\n",
    "        accuracy = accuracy_score(gold_author_ints,\n",
    "                  silver_author_ints)\n",
    "\n",
    "    return f1,precision,recall,accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth_file,predictions_file):\n",
    "    # Calculates evaluation measures for a single attribution problem\n",
    "    gt = {}\n",
    "    with open(ground_truth_file, 'r') as f:\n",
    "        for attrib in json.load(f)['ground_truth']:\n",
    "            gt[attrib['unknown-text']] = attrib['true-author']\n",
    "\n",
    "    pred = {}\n",
    "    with open(predictions_file, 'r') as f:\n",
    "        for attrib in json.load(f):\n",
    "            if attrib['unknown-text'] not in pred:\n",
    "                pred[attrib['unknown-text']] = attrib['predicted-author']\n",
    "    f1,precision,recall,accuracy =  eval_measures(gt,pred)\n",
    "    return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    \"\"\"Convert a sparse array into a dense array.\"\"\"\n",
    "\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\" Return a dense version of the input array.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples] (default: None)\n",
    "        Returns\n",
    "        ---------\n",
    "        X_dense : dense version of the input X array.\n",
    "        \"\"\"\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" Mock method. Does nothing.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples] (default: None)\n",
    "        Returns\n",
    "        ---------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\" Return a dense version of the input array.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples] (default: None)\n",
    "        Returns\n",
    "        ---------\n",
    "        X_dense : dense version of the input X array.\n",
    "        \"\"\"\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examinando o parametro min_df isoladamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runML(problem):\n",
    "    print (\"\\nProblem: %s,  language: %s, \" %(problem['problem'],problem['language']))\n",
    "    \n",
    "    train_docs, train_labels, _   = zip(*problem['candidates'])\n",
    "    problem['training_docs_size'] = len(train_docs);\n",
    "    test_docs, _, test_filename   = zip(*problem['unknown'])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect',   TfidfVectorizer(analyzer='char',\n",
    "                                   min_df=0.05,\n",
    "                                   max_df=1.0,\n",
    "                                   norm='l1',\n",
    "                                   ngram_range=(3,5),\n",
    "                                   sublinear_tf=True,\n",
    "                                   smooth_idf=True,\n",
    "                                   lowercase =False)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # uncommenting more parameters will give better exploring power but will\n",
    "    # increase processing time in a combinatorial way\n",
    "    parameters = {\n",
    "        'vect__min_df':(2,0.01,0.05,0.1)\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline,\n",
    "                               parameters,\n",
    "                               cv=5,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=False,\n",
    "                               scoring='f1_macro')\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, train_labels)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    train_pred=grid_search.predict(train_docs);\n",
    "    test_pred=grid_search.predict(test_docs);\n",
    "    \n",
    "    \n",
    "    # Writing output file\n",
    "    out_data=[]\n",
    "    for i,v in enumerate(test_pred):\n",
    "        out_data.append({'unknown-text': test_filename[i],'predicted-author': v})\n",
    "    answerFile = pathjoin(outputDir,'answers-'+problem['problem']+'.json');\n",
    "    with open(answerFile, 'w') as f:\n",
    "        json.dump(out_data, f, indent=4)\n",
    "    \n",
    "    \n",
    "    #evaluation train\n",
    "    f1,precision,recall,accuracy=evaluate(\n",
    "                pathjoin(inputDir, problem['problem'], 'ground-truth.json'),\n",
    "                answerFile)\n",
    "    \n",
    "    return {\n",
    "                'problem-name'  :       problem['problem'],\n",
    "                \"language\"      :       problem['language'],\n",
    "                'AuthorCount'   :       len(set(train_labels)),\n",
    "                \"train_doc_size\":       len(train_docs),\n",
    "                \"train_caract_per_doc\": sum([len(l) for l in train_docs])/len(train_docs),\n",
    "                \"test_doc_size\" :       len(test_docs),\n",
    "                \"test_caract_per_doc\":  sum([len(l) for l in test_docs])/len(test_docs),\n",
    "                \n",
    "                'macro-f1'       : round(f1,3),\n",
    "                'macro-precision': round(precision,3),\n",
    "                'macro-recall'   : round(recall,3),\n",
    "                'micro-accuracy' : round(accuracy,3),\n",
    "                \n",
    "        }, grid_search.cv_results_, best_parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: problem00001,  language: en, \n",
      "Performing grid search...\n",
      "done in 38.968s\n",
      "Best score: 0.769\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00002,  language: en, \n",
      "Performing grid search...\n",
      "done in 29.814s\n",
      "Best score: 0.874\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.1\n",
      "\n",
      "Problem: problem00003,  language: fr, \n",
      "Performing grid search...\n",
      "done in 89.584s\n",
      "Best score: 0.775\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00004,  language: fr, \n",
      "Performing grid search...\n",
      "done in 31.481s\n",
      "Best score: 0.903\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00005,  language: it, \n",
      "Performing grid search...\n",
      "done in 91.047s\n",
      "Best score: 0.743\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00006,  language: it, \n",
      "Performing grid search...\n",
      "done in 33.172s\n",
      "Best score: 0.970\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n",
      "\n",
      "Problem: problem00007,  language: pl, \n",
      "Performing grid search...\n",
      "done in 135.618s\n",
      "Best score: 0.811\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00008,  language: pl, \n",
      "Performing grid search...\n",
      "done in 49.869s\n",
      "Best score: 0.851\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.1\n",
      "\n",
      "Problem: problem00009,  language: sp, \n",
      "Performing grid search...\n",
      "done in 104.835s\n",
      "Best score: 0.917\n",
      "Best parameters set:\n",
      "\tvect__min_df: 0.01\n",
      "\n",
      "Problem: problem00010,  language: sp, \n",
      "Performing grid search...\n",
      "done in 37.666s\n",
      "Best score: 0.893\n",
      "Best parameters set:\n",
      "\tvect__min_df: 2\n"
     ]
    }
   ],
   "source": [
    "result = [];\n",
    "cv_result = [];\n",
    "best_parameters = [];\n",
    "for problem in problems:\n",
    "    r, c, b = runML(problem);\n",
    "    result.append(r);\n",
    "    cv_result.append(c);\n",
    "    b['problem'] = problem['problem'];\n",
    "    best_parameters.append(b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>vect__min_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem00001</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem00002</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem00003</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem00004</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem00005</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem00006</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>problem00007</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>problem00008</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>problem00009</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>problem00010</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        problem  vect__min_df\n",
       "0  problem00001          0.01\n",
       "1  problem00002          0.10\n",
       "2  problem00003          0.01\n",
       "3  problem00004          0.01\n",
       "4  problem00005          2.00\n",
       "5  problem00006          2.00\n",
       "6  problem00007          0.01\n",
       "7  problem00008          0.10\n",
       "8  problem00009          0.01\n",
       "9  problem00010          2.00"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(best_parameters)[['problem','vect__min_df']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analisando os demais parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runML(problem):\n",
    "    print (\"\\nProblem: %s,  language: %s, \" %(problem['problem'],problem['language']))\n",
    "    \n",
    "    train_docs, train_labels, _   = zip(*problem['candidates'])\n",
    "    problem['training_docs_size'] = len(train_docs);\n",
    "    test_docs, _, test_filename   = zip(*problem['unknown'])\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect',   TfidfVectorizer(analyzer='char',\n",
    "                                   min_df=0.01,\n",
    "                                   max_df=1.0,\n",
    "                                   norm='l1',\n",
    "                                   lowercase =False,\n",
    "                                   sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA()),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # uncommenting more parameters will give better exploring power but will\n",
    "    # increase processing time in a combinatorial way\n",
    "    parameters = {\n",
    "        'vect__ngram_range':((2,3),(2,4),(2,5),(3,5)),\n",
    "        'vect__sublinear_tf':(True, False),\n",
    "        'transf__n_components': (0.1,0.5,0.9,0.999),\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline,\n",
    "                               parameters,\n",
    "                               cv=5,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=False,\n",
    "                               scoring='f1_macro')\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, train_labels)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    train_pred=grid_search.predict(train_docs);\n",
    "    test_pred=grid_search.predict(test_docs);\n",
    "    \n",
    "    \n",
    "    # Writing output file\n",
    "    out_data=[]\n",
    "    for i,v in enumerate(test_pred):\n",
    "        out_data.append({'unknown-text': test_filename[i],'predicted-author': v})\n",
    "    answerFile = pathjoin(outputDir,'answers-'+problem['problem']+'.json');\n",
    "    with open(answerFile, 'w') as f:\n",
    "        json.dump(out_data, f, indent=4)\n",
    "    \n",
    "    \n",
    "    #evaluation train\n",
    "    f1,precision,recall,accuracy=evaluate(\n",
    "                pathjoin(inputDir, problem['problem'], 'ground-truth.json'),\n",
    "                answerFile)\n",
    "    \n",
    "    return {\n",
    "                'problem-name'  :       problem['problem'],\n",
    "                \"language\"      :       problem['language'],\n",
    "                'AuthorCount'   :       len(set(train_labels)),\n",
    "                \"train_doc_size\":       len(train_docs),\n",
    "                \"train_caract_per_doc\": sum([len(l) for l in train_docs])/len(train_docs),\n",
    "                \"test_doc_size\" :       len(test_docs),\n",
    "                \"test_caract_per_doc\":  sum([len(l) for l in test_docs])/len(test_docs),\n",
    "                \n",
    "                'macro-f1'       : round(f1,3),\n",
    "                'macro-precision': round(precision,3),\n",
    "                'macro-recall'   : round(recall,3),\n",
    "                'micro-accuracy' : round(accuracy,3),\n",
    "                \n",
    "        }, grid_search.cv_results_,best_parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem: problem00001,  language: en, \n",
      "Performing grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 403.880s\n",
      "Best score: 0.795\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.999\n",
      "\tvect__ngram_range: (2, 5)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00002,  language: en, \n",
      "Performing grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 78.266s\n",
      "Best score: 0.939\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.5\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00003,  language: fr, \n",
      "Performing grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joseeleandrocustodio/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 439.965s\n",
      "Best score: 0.778\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.999\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: False\n",
      "\n",
      "Problem: problem00004,  language: fr, \n",
      "Performing grid search...\n",
      "done in 79.885s\n",
      "Best score: 0.903\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00005,  language: it, \n",
      "Performing grid search...\n",
      "done in 476.523s\n",
      "Best score: 0.763\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.999\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00006,  language: it, \n",
      "Performing grid search...\n",
      "done in 97.915s\n",
      "Best score: 0.970\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: False\n",
      "\n",
      "Problem: problem00007,  language: pl, \n",
      "Performing grid search...\n",
      "done in 769.338s\n",
      "Best score: 0.842\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.999\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: False\n",
      "\n",
      "Problem: problem00008,  language: pl, \n",
      "Performing grid search...\n",
      "done in 123.100s\n",
      "Best score: 0.882\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (2, 4)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00009,  language: sp, \n",
      "Performing grid search...\n",
      "done in 499.174s\n",
      "Best score: 0.923\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.9\n",
      "\tvect__ngram_range: (2, 5)\n",
      "\tvect__sublinear_tf: True\n",
      "\n",
      "Problem: problem00010,  language: sp, \n",
      "Performing grid search...\n",
      "done in 131.791s\n",
      "Best score: 0.893\n",
      "Best parameters set:\n",
      "\ttransf__n_components: 0.999\n",
      "\tvect__ngram_range: (2, 3)\n",
      "\tvect__sublinear_tf: False\n"
     ]
    }
   ],
   "source": [
    "result = [];\n",
    "cv_result = [];\n",
    "best_parameters = [];\n",
    "for problem in problems:\n",
    "    r, c, b = runML(problem);\n",
    "    result.append(r);\n",
    "    cv_result.append(c);\n",
    "    b['problem'] = problem['problem'];\n",
    "    best_parameters.append(b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(result)[['problem-name',\n",
    "                     \"language\",\n",
    "                     'AuthorCount',\n",
    "                     \"train_doc_size\",\"train_caract_per_doc\",\n",
    "                     \"test_doc_size\", \"test_caract_per_doc\",\n",
    "                     'macro-f1','macro-precision','macro-recall' ,'micro-accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem-name</th>\n",
       "      <th>language</th>\n",
       "      <th>AuthorCount</th>\n",
       "      <th>train_doc_size</th>\n",
       "      <th>train_caract_per_doc</th>\n",
       "      <th>test_doc_size</th>\n",
       "      <th>test_caract_per_doc</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>macro-precision</th>\n",
       "      <th>macro-recall</th>\n",
       "      <th>micro-accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>problem00001</td>\n",
       "      <td>en</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4327</td>\n",
       "      <td>105</td>\n",
       "      <td>4370</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem00002</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4342</td>\n",
       "      <td>21</td>\n",
       "      <td>4296</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>problem00003</td>\n",
       "      <td>fr</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4492</td>\n",
       "      <td>49</td>\n",
       "      <td>4508</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>problem00004</td>\n",
       "      <td>fr</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4522</td>\n",
       "      <td>21</td>\n",
       "      <td>4532</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem00005</td>\n",
       "      <td>it</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4720</td>\n",
       "      <td>80</td>\n",
       "      <td>4787</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>problem00006</td>\n",
       "      <td>it</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4847</td>\n",
       "      <td>46</td>\n",
       "      <td>4765</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>problem00007</td>\n",
       "      <td>pl</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>5145</td>\n",
       "      <td>103</td>\n",
       "      <td>5200</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>problem00008</td>\n",
       "      <td>pl</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>5049</td>\n",
       "      <td>15</td>\n",
       "      <td>5214</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>problem00009</td>\n",
       "      <td>sp</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>4794</td>\n",
       "      <td>117</td>\n",
       "      <td>4788</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>problem00010</td>\n",
       "      <td>sp</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>4955</td>\n",
       "      <td>64</td>\n",
       "      <td>4827</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem-name language  AuthorCount  train_doc_size  train_caract_per_doc  \\\n",
       "0  problem00001       en           20             140                  4327   \n",
       "1  problem00002       en            5              35                  4342   \n",
       "2  problem00003       fr           20             140                  4492   \n",
       "3  problem00004       fr            5              35                  4522   \n",
       "4  problem00005       it           20             140                  4720   \n",
       "5  problem00006       it            5              35                  4847   \n",
       "6  problem00007       pl           20             140                  5145   \n",
       "7  problem00008       pl            5              35                  5049   \n",
       "8  problem00009       sp           20             140                  4794   \n",
       "9  problem00010       sp            5              35                  4955   \n",
       "\n",
       "   test_doc_size  test_caract_per_doc  macro-f1  macro-precision  \\\n",
       "0            105                 4370     0.645            0.650   \n",
       "1             21                 4296     0.503            0.567   \n",
       "2             49                 4508     0.693            0.697   \n",
       "3             21                 4532     0.820            0.820   \n",
       "4             80                 4787     0.605            0.593   \n",
       "5             46                 4765     0.589            0.593   \n",
       "6            103                 5200     0.478            0.499   \n",
       "7             15                 5214     0.668            0.667   \n",
       "8            117                 4788     0.790            0.786   \n",
       "9             64                 4827     0.850            0.865   \n",
       "\n",
       "   macro-recall  micro-accuracy  \n",
       "0         0.761           0.686  \n",
       "1         0.533           0.429  \n",
       "2         0.753           0.735  \n",
       "3         0.870           0.762  \n",
       "4         0.721           0.688  \n",
       "5         0.698           0.826  \n",
       "6         0.565           0.544  \n",
       "7         0.678           0.800  \n",
       "8         0.850           0.812  \n",
       "9         0.855           0.891  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rr}\n",
      "\\toprule\n",
      " index &  macro-f1 \\\\\n",
      "\\midrule\n",
      " 0 & 0.645 \\\\\n",
      " 1 & 0.503 \\\\\n",
      " 2 & 0.693 \\\\\n",
      " 3 & 0.820 \\\\\n",
      " 4 & 0.605 \\\\\n",
      " 5 & 0.589 \\\\\n",
      " 6 & 0.478 \\\\\n",
      " 7 & 0.668 \\\\\n",
      " 8 & 0.790 \\\\\n",
      " 9 & 0.850 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"macro-f1\"]].reset_index().to_latex(index=False).replace(\"     \",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages={\n",
    "    'en':'inglesa',\n",
    "    'sp':'espanhola',\n",
    "    'it':'italiana',\n",
    "    'pl':'polonesa',\n",
    "    'fr':'francesa'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result2 = [];\n",
    "dfCV = pd.DataFrame();\n",
    "for i, c in enumerate(cv_result):\n",
    "    temp = pd.DataFrame(c);\n",
    "    temp['problem'] = i+1;\n",
    "    temp['language'] = languages[problems[i]['language']]\n",
    "    dfCV = dfCV.append(temp);\n",
    "\n",
    "for p in ['param_transf__n_components',\n",
    "    'mean_test_score','std_test_score','mean_train_score',   \n",
    "    'split0_test_score','split0_train_score',\n",
    "    'split1_test_score','split1_train_score',\n",
    "    'split2_test_score','split2_train_score',\n",
    "    'split3_test_score','split3_train_score',\n",
    "    'split4_test_score','split4_train_score']:\n",
    "    dfCV[p]=dfCV[p].astype(np.float32);\n",
    "\n",
    "    \n",
    "dfCV =dfCV[[\n",
    "    'problem',\n",
    "    'language',\n",
    "    'rank_test_score',\n",
    "    'param_transf__n_components',\n",
    "    'param_vect__ngram_range',\n",
    "    'param_vect__sublinear_tf',\n",
    "    'mean_test_score',   \n",
    "    'std_test_score',\n",
    "    'mean_train_score',   \n",
    "\n",
    "    'split0_test_score','split0_train_score',\n",
    "    'split1_test_score','split1_train_score',\n",
    "    'split2_test_score','split2_train_score',\n",
    "    'split3_test_score','split3_train_score',\n",
    "    'split4_test_score','split4_train_score',\n",
    "\n",
    "    'mean_score_time',\n",
    "    'mean_fit_time',\n",
    "    'std_fit_time',\n",
    "    'std_score_time',\n",
    "    'std_train_score',\n",
    "]];\n",
    "\n",
    "dfCV.rename(columns={\n",
    "    'param_transf__n_components':'PCA_componentes',\n",
    "    'param_vect__ngram_range':'ngram_range',\n",
    "    'param_vect__sublinear_tf':'sublinear_tf',\n",
    "    'param_vect__smooth_idf':'smooth_idf'\n",
    "},inplace=True);\n",
    "\n",
    "#print('\\',\\n\\''.join(dfCV.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCV.to_csv('PANAA2018_CHAR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>language</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>sublinear_tf</th>\n",
       "      <th>PCA_componentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.087330</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>inglesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939048</td>\n",
       "      <td>0.052786</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777619</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(3, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>francesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>italiana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.047139</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>italiana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969524</td>\n",
       "      <td>0.048187</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>italiana</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969524</td>\n",
       "      <td>0.048187</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841905</td>\n",
       "      <td>0.081394</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.136427</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.136427</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>polonesa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.136427</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.088845</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.088845</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.110410</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>espanhola</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.110410</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    problem   language  rank_test_score  mean_test_score  std_test_score  \\\n",
       "28        1    inglesa                1         0.795238        0.087330   \n",
       "10        2    inglesa                1         0.939048        0.052786   \n",
       "27        3   francesa                1         0.777619        0.102329   \n",
       "30        4   francesa                1         0.902857        0.113689   \n",
       "22        4   francesa                1         0.902857        0.113689   \n",
       "31        4   francesa                1         0.902857        0.113689   \n",
       "28        4   francesa                1         0.902857        0.113689   \n",
       "20        4   francesa                1         0.902857        0.113689   \n",
       "29        4   francesa                1         0.902857        0.113689   \n",
       "26        4   francesa                1         0.902857        0.113689   \n",
       "18        4   francesa                1         0.902857        0.113689   \n",
       "27        4   francesa                1         0.902857        0.113689   \n",
       "19        4   francesa                1         0.902857        0.113689   \n",
       "26        5   italiana                1         0.763469        0.047139   \n",
       "27        6   italiana                1         0.969524        0.048187   \n",
       "19        6   italiana                1         0.969524        0.048187   \n",
       "27        7   polonesa                1         0.841905        0.081394   \n",
       "26        8   polonesa                1         0.881905        0.136427   \n",
       "18        8   polonesa                1         0.881905        0.136427   \n",
       "27        8   polonesa                1         0.881905        0.136427   \n",
       "28        9  espanhola                1         0.922857        0.088845   \n",
       "20        9  espanhola                1         0.922857        0.088845   \n",
       "27       10  espanhola                1         0.893333        0.110410   \n",
       "25       10  espanhola                1         0.893333        0.110410   \n",
       "\n",
       "   ngram_range sublinear_tf  PCA_componentes  \n",
       "28      (2, 5)         True            0.999  \n",
       "10      (2, 4)         True            0.500  \n",
       "27      (2, 4)        False            0.999  \n",
       "30      (3, 5)         True            0.999  \n",
       "22      (3, 5)         True            0.900  \n",
       "31      (3, 5)        False            0.999  \n",
       "28      (2, 5)         True            0.999  \n",
       "20      (2, 5)         True            0.900  \n",
       "29      (2, 5)        False            0.999  \n",
       "26      (2, 4)         True            0.999  \n",
       "18      (2, 4)         True            0.900  \n",
       "27      (2, 4)        False            0.999  \n",
       "19      (2, 4)        False            0.900  \n",
       "26      (2, 4)         True            0.999  \n",
       "27      (2, 4)        False            0.999  \n",
       "19      (2, 4)        False            0.900  \n",
       "27      (2, 4)        False            0.999  \n",
       "26      (2, 4)         True            0.999  \n",
       "18      (2, 4)         True            0.900  \n",
       "27      (2, 4)        False            0.999  \n",
       "28      (2, 5)         True            0.999  \n",
       "20      (2, 5)         True            0.900  \n",
       "27      (2, 4)        False            0.999  \n",
       "25      (2, 3)        False            0.999  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dfCV[dfCV.rank_test_score == 1])[\n",
    "    ['problem',\n",
    "     'language',\n",
    "    'rank_test_score',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "    'ngram_range',\n",
    "    'sublinear_tf',\n",
    "    'PCA_componentes']\n",
    "].sort_values(by=[\n",
    "    'problem',\n",
    "    'mean_test_score',\n",
    "    'ngram_range',\n",
    "    'sublinear_tf',\n",
    "    'PCA_componentes'\n",
    "], ascending=[True, False,False,False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sublinear_tf</th>\n",
       "      <th colspan=\"4\" halign=\"left\">False</th>\n",
       "      <th colspan=\"4\" halign=\"left\">True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>(2, 3)</th>\n",
       "      <th>(2, 4)</th>\n",
       "      <th>(2, 5)</th>\n",
       "      <th>(3, 5)</th>\n",
       "      <th>(2, 3)</th>\n",
       "      <th>(2, 4)</th>\n",
       "      <th>(2, 5)</th>\n",
       "      <th>(3, 5)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem</th>\n",
       "      <th>language</th>\n",
       "      <th>PCA_componentes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">inglesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.322358</td>\n",
       "      <td>0.264718</td>\n",
       "      <td>0.160758</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>0.302766</td>\n",
       "      <td>0.225138</td>\n",
       "      <td>0.193163</td>\n",
       "      <td>0.190537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.628095</td>\n",
       "      <td>0.656893</td>\n",
       "      <td>0.701429</td>\n",
       "      <td>0.678878</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.718571</td>\n",
       "      <td>0.732857</td>\n",
       "      <td>0.717619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.657925</td>\n",
       "      <td>0.742279</td>\n",
       "      <td>0.751497</td>\n",
       "      <td>0.747925</td>\n",
       "      <td>0.726429</td>\n",
       "      <td>0.785238</td>\n",
       "      <td>0.794762</td>\n",
       "      <td>0.770952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.704422</td>\n",
       "      <td>0.753878</td>\n",
       "      <td>0.766735</td>\n",
       "      <td>0.762517</td>\n",
       "      <td>0.731905</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.768571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">inglesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.415782</td>\n",
       "      <td>0.423810</td>\n",
       "      <td>0.221587</td>\n",
       "      <td>0.221587</td>\n",
       "      <td>0.391973</td>\n",
       "      <td>0.367891</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.221905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.939048</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.817143</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.817143</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.855238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.798095</td>\n",
       "      <td>0.836190</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.817143</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.855238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">francesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.311735</td>\n",
       "      <td>0.215081</td>\n",
       "      <td>0.209250</td>\n",
       "      <td>0.169491</td>\n",
       "      <td>0.224235</td>\n",
       "      <td>0.189577</td>\n",
       "      <td>0.193594</td>\n",
       "      <td>0.168061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.718810</td>\n",
       "      <td>0.718571</td>\n",
       "      <td>0.720714</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.748095</td>\n",
       "      <td>0.723333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.748810</td>\n",
       "      <td>0.753810</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.756190</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.767619</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.761667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.750476</td>\n",
       "      <td>0.777619</td>\n",
       "      <td>0.763333</td>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>0.774762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">francesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.279048</td>\n",
       "      <td>0.368844</td>\n",
       "      <td>0.327755</td>\n",
       "      <td>0.344762</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.216190</td>\n",
       "      <td>0.153968</td>\n",
       "      <td>0.195238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.665714</td>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.729524</td>\n",
       "      <td>0.815238</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.843810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.869524</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.864762</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.902857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.839048</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.872381</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.902857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">italiana</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.295484</td>\n",
       "      <td>0.246480</td>\n",
       "      <td>0.128672</td>\n",
       "      <td>0.124444</td>\n",
       "      <td>0.265147</td>\n",
       "      <td>0.241454</td>\n",
       "      <td>0.139478</td>\n",
       "      <td>0.138798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.677211</td>\n",
       "      <td>0.646259</td>\n",
       "      <td>0.643834</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>0.664184</td>\n",
       "      <td>0.672211</td>\n",
       "      <td>0.676803</td>\n",
       "      <td>0.679116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.707687</td>\n",
       "      <td>0.716723</td>\n",
       "      <td>0.725295</td>\n",
       "      <td>0.686156</td>\n",
       "      <td>0.725374</td>\n",
       "      <td>0.736973</td>\n",
       "      <td>0.720306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.686258</td>\n",
       "      <td>0.707755</td>\n",
       "      <td>0.730850</td>\n",
       "      <td>0.730850</td>\n",
       "      <td>0.697347</td>\n",
       "      <td>0.763469</td>\n",
       "      <td>0.757211</td>\n",
       "      <td>0.737211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">italiana</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.465714</td>\n",
       "      <td>0.217551</td>\n",
       "      <td>0.270748</td>\n",
       "      <td>0.259048</td>\n",
       "      <td>0.193333</td>\n",
       "      <td>0.207273</td>\n",
       "      <td>0.184762</td>\n",
       "      <td>0.150159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.900952</td>\n",
       "      <td>0.900952</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.900952</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.900952</td>\n",
       "      <td>0.969524</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.900952</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.900952</td>\n",
       "      <td>0.969524</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.900952</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.931429</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">7</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">polonesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.265396</td>\n",
       "      <td>0.265548</td>\n",
       "      <td>0.243823</td>\n",
       "      <td>0.398919</td>\n",
       "      <td>0.270634</td>\n",
       "      <td>0.265620</td>\n",
       "      <td>0.242428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.789524</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.790714</td>\n",
       "      <td>0.779286</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.790952</td>\n",
       "      <td>0.800952</td>\n",
       "      <td>0.776905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.812619</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.823878</td>\n",
       "      <td>0.823401</td>\n",
       "      <td>0.823333</td>\n",
       "      <td>0.802381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.841905</td>\n",
       "      <td>0.811905</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.841020</td>\n",
       "      <td>0.825782</td>\n",
       "      <td>0.820952</td>\n",
       "      <td>0.811429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">8</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">polonesa</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.324082</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.202177</td>\n",
       "      <td>0.202177</td>\n",
       "      <td>0.274558</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.108398</td>\n",
       "      <td>0.068571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.708844</td>\n",
       "      <td>0.635510</td>\n",
       "      <td>0.630748</td>\n",
       "      <td>0.775238</td>\n",
       "      <td>0.708844</td>\n",
       "      <td>0.693605</td>\n",
       "      <td>0.693605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.824762</td>\n",
       "      <td>0.732653</td>\n",
       "      <td>0.732653</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.781224</td>\n",
       "      <td>0.781224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.881905</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.824762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">9</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">espanhola</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.375880</td>\n",
       "      <td>0.318273</td>\n",
       "      <td>0.264487</td>\n",
       "      <td>0.257703</td>\n",
       "      <td>0.298123</td>\n",
       "      <td>0.272538</td>\n",
       "      <td>0.160580</td>\n",
       "      <td>0.140193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.766429</td>\n",
       "      <td>0.790714</td>\n",
       "      <td>0.779830</td>\n",
       "      <td>0.763810</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.831905</td>\n",
       "      <td>0.809116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.907619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.848571</td>\n",
       "      <td>0.856905</td>\n",
       "      <td>0.874286</td>\n",
       "      <td>0.873810</td>\n",
       "      <td>0.837619</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.917143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">espanhola</th>\n",
       "      <th>0.100</th>\n",
       "      <td>0.548571</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.311429</td>\n",
       "      <td>0.263492</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.332653</td>\n",
       "      <td>0.315873</td>\n",
       "      <td>0.322857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.649524</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.900</th>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999</th>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.855238</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sublinear_tf                          False                                \\\n",
       "ngram_range                          (2, 3)    (2, 4)    (2, 5)    (3, 5)   \n",
       "problem language  PCA_componentes                                           \n",
       "1       inglesa   0.100            0.322358  0.264718  0.160758  0.158876   \n",
       "                  0.500            0.628095  0.656893  0.701429  0.678878   \n",
       "                  0.900            0.657925  0.742279  0.751497  0.747925   \n",
       "                  0.999            0.704422  0.753878  0.766735  0.762517   \n",
       "2       inglesa   0.100            0.415782  0.423810  0.221587  0.221587   \n",
       "                  0.500            0.780952  0.874286  0.874286  0.874286   \n",
       "                  0.900            0.828571  0.798095  0.817143  0.790476   \n",
       "                  0.999            0.798095  0.836190  0.855238  0.855238   \n",
       "3       francesa  0.100            0.311735  0.215081  0.209250  0.169491   \n",
       "                  0.500            0.658333  0.718810  0.718571  0.720714   \n",
       "                  0.900            0.748810  0.753810  0.765714  0.756190   \n",
       "                  0.999            0.750476  0.777619  0.763333  0.772857   \n",
       "4       francesa  0.100            0.279048  0.368844  0.327755  0.344762   \n",
       "                  0.500            0.665714  0.737143  0.693333  0.811429   \n",
       "                  0.900            0.869524  0.902857  0.874286  0.843810   \n",
       "                  0.999            0.839048  0.902857  0.902857  0.902857   \n",
       "5       italiana  0.100            0.295484  0.246480  0.128672  0.124444   \n",
       "                  0.500            0.677211  0.646259  0.643834  0.665635   \n",
       "                  0.900            0.675000  0.707687  0.716723  0.725295   \n",
       "                  0.999            0.686258  0.707755  0.730850  0.730850   \n",
       "6       italiana  0.100            0.465714  0.217551  0.270748  0.259048   \n",
       "                  0.500            0.900952  0.900952  0.893333  0.931429   \n",
       "                  0.900            0.900952  0.969524  0.893333  0.893333   \n",
       "                  0.999            0.900952  0.969524  0.931429  0.931429   \n",
       "7       polonesa  0.100            0.390786  0.265396  0.265548  0.243823   \n",
       "                  0.500            0.789524  0.795238  0.790714  0.779286   \n",
       "                  0.900            0.823810  0.812619  0.811429  0.811429   \n",
       "                  0.999            0.821429  0.841905  0.811905  0.800000   \n",
       "8       polonesa  0.100            0.324082  0.141414  0.202177  0.202177   \n",
       "                  0.500            0.794286  0.708844  0.635510  0.630748   \n",
       "                  0.900            0.874286  0.824762  0.732653  0.732653   \n",
       "                  0.999            0.874286  0.881905  0.851429  0.851429   \n",
       "9       espanhola 0.100            0.375880  0.318273  0.264487  0.257703   \n",
       "                  0.500            0.766429  0.790714  0.779830  0.763810   \n",
       "                  0.900            0.847619  0.838095  0.855238  0.856667   \n",
       "                  0.999            0.848571  0.856905  0.874286  0.873810   \n",
       "10      espanhola 0.100            0.548571  0.504444  0.311429  0.263492   \n",
       "                  0.500            0.809524  0.649524  0.752381  0.752381   \n",
       "                  0.900            0.855238  0.855238  0.855238  0.855238   \n",
       "                  0.999            0.893333  0.893333  0.855238  0.855238   \n",
       "\n",
       "sublinear_tf                          True                                 \n",
       "ngram_range                          (2, 3)    (2, 4)    (2, 5)    (3, 5)  \n",
       "problem language  PCA_componentes                                          \n",
       "1       inglesa   0.100            0.302766  0.225138  0.193163  0.190537  \n",
       "                  0.500            0.685000  0.718571  0.732857  0.717619  \n",
       "                  0.900            0.726429  0.785238  0.794762  0.770952  \n",
       "                  0.999            0.731905  0.785714  0.795238  0.768571  \n",
       "2       inglesa   0.100            0.391973  0.367891  0.228571  0.221905  \n",
       "                  0.500            0.809524  0.939048  0.904762  0.828571  \n",
       "                  0.900            0.817143  0.855238  0.855238  0.855238  \n",
       "                  0.999            0.817143  0.855238  0.855238  0.855238  \n",
       "3       francesa  0.100            0.224235  0.189577  0.193594  0.168061  \n",
       "                  0.500            0.740476  0.738333  0.748095  0.723333  \n",
       "                  0.900            0.761905  0.767619  0.761667  0.761667  \n",
       "                  0.999            0.760714  0.747619  0.775714  0.774762  \n",
       "4       francesa  0.100            0.238095  0.216190  0.153968  0.195238  \n",
       "                  0.500            0.729524  0.815238  0.843810  0.843810  \n",
       "                  0.900            0.864762  0.902857  0.902857  0.902857  \n",
       "                  0.999            0.872381  0.902857  0.902857  0.902857  \n",
       "5       italiana  0.100            0.265147  0.241454  0.139478  0.138798  \n",
       "                  0.500            0.664184  0.672211  0.676803  0.679116  \n",
       "                  0.900            0.686156  0.725374  0.736973  0.720306  \n",
       "                  0.999            0.697347  0.763469  0.757211  0.737211  \n",
       "6       italiana  0.100            0.193333  0.207273  0.184762  0.150159  \n",
       "                  0.500            0.931429  0.900952  0.893333  0.893333  \n",
       "                  0.900            0.900952  0.931429  0.893333  0.893333  \n",
       "                  0.999            0.900952  0.931429  0.931429  0.893333  \n",
       "7       polonesa  0.100            0.398919  0.270634  0.265620  0.242428  \n",
       "                  0.500            0.806667  0.790952  0.800952  0.776905  \n",
       "                  0.900            0.823878  0.823401  0.823333  0.802381  \n",
       "                  0.999            0.841020  0.825782  0.820952  0.811429  \n",
       "8       polonesa  0.100            0.274558  0.245397  0.108398  0.068571  \n",
       "                  0.500            0.775238  0.708844  0.693605  0.693605  \n",
       "                  0.900            0.853333  0.881905  0.781224  0.781224  \n",
       "                  0.999            0.853333  0.881905  0.851429  0.824762  \n",
       "9       espanhola 0.100            0.298123  0.272538  0.160580  0.140193  \n",
       "                  0.500            0.830000  0.847619  0.831905  0.809116  \n",
       "                  0.900            0.843810  0.888571  0.922857  0.907619  \n",
       "                  0.999            0.837619  0.913333  0.922857  0.917143  \n",
       "10      espanhola 0.100            0.523810  0.332653  0.315873  0.322857  \n",
       "                  0.500            0.814286  0.814286  0.860000  0.860000  \n",
       "                  0.900            0.890476  0.860000  0.885714  0.885714  \n",
       "                  0.999            0.890476  0.890476  0.885714  0.885714  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCV.pivot_table(\n",
    "            index=['problem','language','PCA_componentes'],\n",
    "            columns=['sublinear_tf', 'ngram_range'],\n",
    "            values='mean_test_score'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\caption{Medida F1 para os parâmetros }\n",
      "\\begin{tabular}{lllrrrr}\n",
      "\\toprule\n",
      "   &   & ngram\\_range &  (2, 3) &  (2, 4) &  (2, 5) &  (3, 5) \\\\\n",
      "problem & language & sublinear\\_tf &     &     &     &     \\\\\n",
      "\\midrule\n",
      "1  & inglesa & False &   0.704 &   0.754 &   0.767 &   0.763 \\\\\n",
      "   &   & True  &   0.732 &   0.786 &   0.795 &   0.769 \\\\\n",
      "2  & inglesa & False &   0.798 &   0.836 &   0.855 &   0.855 \\\\\n",
      "   &   & True  &   0.817 &   0.855 &   0.855 &   0.855 \\\\\n",
      "3  & francesa & False &   0.750 &   0.778 &   0.763 &   0.773 \\\\\n",
      "   &   & True  &   0.761 &   0.748 &   0.776 &   0.775 \\\\\n",
      "4  & francesa & False &   0.839 &   0.903 &   0.903 &   0.903 \\\\\n",
      "   &   & True  &   0.872 &   0.903 &   0.903 &   0.903 \\\\\n",
      "5  & italiana & False &   0.686 &   0.708 &   0.731 &   0.731 \\\\\n",
      "   &   & True  &   0.697 &   0.763 &   0.757 &   0.737 \\\\\n",
      "6  & italiana & False &   0.901 &   0.970 &   0.931 &   0.931 \\\\\n",
      "   &   & True  &   0.901 &   0.931 &   0.931 &   0.893 \\\\\n",
      "7  & polonesa & False &   0.821 &   0.842 &   0.812 &   0.800 \\\\\n",
      "   &   & True  &   0.841 &   0.826 &   0.821 &   0.811 \\\\\n",
      "8  & polonesa & False &   0.874 &   0.882 &   0.851 &   0.851 \\\\\n",
      "   &   & True  &   0.853 &   0.882 &   0.851 &   0.825 \\\\\n",
      "9  & espanhola & False &   0.849 &   0.857 &   0.874 &   0.874 \\\\\n",
      "   &   & True  &   0.838 &   0.913 &   0.923 &   0.917 \\\\\n",
      "10 & espanhola & False &   0.893 &   0.893 &   0.855 &   0.855 \\\\\n",
      "   &   & True  &   0.890 &   0.890 &   0.886 &   0.886 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\label{tab:modelocaracter}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.precision = 3  \n",
    "print(u\"\\\\begin{table}[h]\\n\\\\centering\\n\\\\caption{Medida F1 para os parâmetros }\")\n",
    "\n",
    "print(dfCV[dfCV.PCA_componentes == 0.999].pivot_table(\n",
    "        index=['problem','language','sublinear_tf'],\n",
    "        columns=['ngram_range'],\n",
    "        values='mean_test_score'\n",
    "    ).to_latex().replace(\"     \",\" \"))\n",
    "print (\"\\label{tab:modelocaracter}\")\n",
    "print(r\"\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2ac461d0>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dfResults[(dfResults.language=='it') & (dfResults.sublinear_tf==True)].plot(x='PCA_componentes',y='mean_test_score', kind='scatter')\n",
    "dfResults[(dfResults.language=='it')& (dfResults.sublinear_tf==False)].plot(x='PCA_componentes',y='mean_test_score', kind='scatter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1010416d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(result)\\\n",
    "    .sort_values(by=['language','problem-name'])[['language','problem-name','macro-f1']]\\\n",
    "    .plot(kind='bar', x=['language','problem-name'], legend=True, figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/>\n",
    "\n",
    "#  Abordagem desafiante 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramSplitter(object):\n",
    "    def __init__(self, text, ngram=(3,3), vocabulary=None):\n",
    "        self.text = text\n",
    "        self.ngram_min = ngram[0]\n",
    "        self.ngram_max = ngram[1];\n",
    "        self.vocabulary = vocabulary;\n",
    "    \n",
    "    def text2ngrams(self,text):\n",
    "        vect = [\n",
    "            text[t:t+j]\n",
    "                for t in xrange(len(text)-self.ngram_max+1)\n",
    "                for j in xrange(self.ngram_min, self.ngram_max+1)\n",
    "        ]\n",
    "        \n",
    "        if self.vocabulary is not None:\n",
    "            return [word for word in vect if word in self.vocabulary];\n",
    "        else:\n",
    "            return [word for word in vect if word]\n",
    " \n",
    "    def __iter__(self):\n",
    "        if isinstance(self.text,list):\n",
    "            for s in self.text:\n",
    "                yield self.text2ngrams(s);\n",
    "        elif isinstance(self.text,str) or isinstance(self.text,unicode):\n",
    "            yield self.text2ngrams(self.text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"A classifier that uses classes embeddings to classify instances\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            ngram = (3,4),\n",
    "            analyzer = 'char',\n",
    "            min_df = 0.3,\n",
    "            max_df = 1.0,\n",
    "        \n",
    "            min_count =2,\n",
    "            embeddingSize =750,\n",
    "            window=10,\n",
    "            algorithm = 0,\n",
    "            iter =10\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Called when initializing the classifier\n",
    "        \"\"\"\n",
    "        self.algorithm     = algorithm\n",
    "        self.min_count     = min_count\n",
    "        self.embeddingSize = embeddingSize\n",
    "        self.window        = window\n",
    "        self.iter          = iter\n",
    "        self.analyzer      = analyzer\n",
    "        self.vocabulary_   = {}\n",
    "        self.ngram         = ngram\n",
    "        self.min_df        = min_df\n",
    "        self.max_df        = max_df\n",
    "\n",
    "    def _buildVectorModel(self, document):\n",
    "        sentenseGenerator = NgramSplitter(document,self.ngram, self.vocabulary_);\n",
    "        \n",
    "        model = Word2Vec(\n",
    "            sentenseGenerator,\n",
    "            sg       = self.algorithm,\n",
    "            iter     = self.iter,        \n",
    "            min_count= self.min_count,\n",
    "            window   = self.window,\n",
    "            size     = self.embeddingSize,\n",
    "            seed=0\n",
    "        );\n",
    "        return model.wv;\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Sumarize one text per labels and transform the text into word vectors\n",
    "        \"\"\"\n",
    "        \n",
    "        #creating author profile\n",
    "        profile = defaultdict(unicode);\n",
    "        for text, label in zip(X,y):\n",
    "            profile[label]+=text;\n",
    "            \n",
    "        #build a global vocaculary / Using count vectorizer to create a fixed vocabulary\n",
    "        vectorizer = CountVectorizer(\n",
    "                analyzer=self.analyzer,\n",
    "                ngram_range=self.ngram,\n",
    "                min_df=self.min_df,\n",
    "                max_df=self.max_df,\n",
    "                lowercase=False\n",
    "        )\n",
    "        vectorizer.fit(X);\n",
    "        self.vocabulary_ = vectorizer.vocabulary_\n",
    "        \n",
    "        # profile vector represent each author in the embedding space\n",
    "        self.profileVectors_ = {y: self._buildVectorModel(profile[y]) for y in y};\n",
    "\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _minmax(self, a):\n",
    "        a = (a - a.min())/(a.max() - a.min());\n",
    "        return a;\n",
    "        \n",
    "    def _simpleCosine(self,a, b):\n",
    "        '''\n",
    "        calculates cosine between array a and b.\n",
    "        This function is used because sklearn similiraty function compares all elements vs all elements\n",
    "        what will not be used. So this function becames handy.\n",
    "        '''\n",
    "        a = a / np.sqrt(np.sum(a **2));\n",
    "        b = b / np.sqrt(np.sum(b **2));\n",
    "        cos = np.sum(np.array(a) * np.array(b));\n",
    "        return cos;\n",
    "    \n",
    "    def _KLD(self,p, q):\n",
    "        p = self._minmax(p); p = p/p.sum();\n",
    "        q = self._minmax(q); q = q/q.sum();\n",
    "        \n",
    "        cond = ((q != 0)&(p != 0));\n",
    "        k1 = np.sum(np.where(cond, p * np.log(p / q), 0));\n",
    "        return k1;\n",
    "    \n",
    "    def _manhattan(self,p, q):\n",
    "        p = self._minmax(p); p = p/p.sum();\n",
    "        q = self._minmax(q); q = q/q.sum();\n",
    "        return np.mean(np.abs(p-q));\n",
    "    \n",
    "    \n",
    "    def _guassian(self, C,D):\n",
    "        cond = C-D !=0;\n",
    "        bc = np.where(cond,(C-D+1)**2/(2*np.maximum(C,D+1)),1);\n",
    "        return np.sum(-np.log(bc));\n",
    "\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        # counts number of values bigger than mean\n",
    "        return(sum(self.predict(X)))\n",
    "    \n",
    "    def _softMax(self,a):\n",
    "        a = self._minmax(a);\n",
    "        a = np.exp(a)/np.sum(np.exp(a))\n",
    "        return a;\n",
    "    \n",
    "    def _predict1Doc(self, docVect):\n",
    "        vocabDoc = set(docVect.vocab.keys());\n",
    "    \n",
    "        metrics = [];\n",
    "        \n",
    "        def c(aa,bb, funct):\n",
    "            voc = set(aa.vocab.keys()) & set(bb.vocab.keys())\n",
    "            f = np.array([\n",
    "                funct(aa[v], bb[v])\n",
    "                for v in voc\n",
    "            ]);\n",
    "            f = np.sum(f)\n",
    "            return f;\n",
    "    \n",
    "        for label in self.profileVectors_:\n",
    "            labelVocab = set(self.profileVectors_[label].vocab.keys());\n",
    "            intersect  = vocabDoc & labelVocab;\n",
    "            union      = len(vocabDoc | labelVocab);\n",
    "            jaccard    = 1.0*len(intersect) / union;\n",
    "            \n",
    "            metrics.append({\n",
    "                'label'       : label,\n",
    "                'jaccard'     : jaccard,\n",
    "                'lenIntersect': len(intersect),\n",
    "                'lenUnion'    : union,\n",
    "                'lenMax'      : max(len(labelVocab), len(vocabDoc)),\n",
    "                'similarity'  : c(docVect, self.profileVectors_[label], self._simpleCosine),\n",
    "                'KLD'         : c(docVect, self.profileVectors_[label], self._KLD),\n",
    "                'manhattan'   : c(docVect, self.profileVectors_[label], self._manhattan),\n",
    "                'guassian'    : c(docVect, self.profileVectors_[label], self._guassian),\n",
    "                \n",
    "            })\n",
    "        #softmax norm\n",
    "        similarity = self._softMax(np.array([c['similarity'] for c in metrics ]));\n",
    "        guassian   = self._softMax(np.array([c['guassian'] for c in metrics ]));\n",
    "        manhattan  = self._softMax(np.array([c['manhattan'] for c in metrics ]));\n",
    "    \n",
    "        #appending normalized sum of distance\n",
    "        for i,c in enumerate(metrics):\n",
    "            c.update({\n",
    "                'similarityNorm': similarity[i],\n",
    "                'guassianNorm': guassian[i],\n",
    "                'manhattanNorm': manhattan[i]\n",
    "            })\n",
    "    \n",
    "        return metrics;\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"profileVectors_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "            \n",
    "        docVectors    = [self._buildVectorModel(x) for x in X];\n",
    "        self.metrics_ = [self._predict1Doc(v)      for v in docVectors];\n",
    "        \n",
    "        result = [];\n",
    "        for r in self.metrics_:\n",
    "            best = r[0];\n",
    "            best['bestMatch'] = True;\n",
    "            for rr in r:\n",
    "                if rr != best:\n",
    "                    rr['bestMatch'] = False;\n",
    "                if rr['similarityNorm'] > best['similarityNorm'] :\n",
    "                    best['bestMatch'] = False;\n",
    "                    best = rr;\n",
    "                    best['bestMatch'] = True;\n",
    "            result.append(best);\n",
    "            \n",
    "        self.predited_ = result;\n",
    "\n",
    "        return([r['label'] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = problems[8];\n",
    "print (\"Problem: %s,  language: %s, \" %(problem['problem'],problem['language']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2VecClassifier();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs, train_labels,_ = zip(*problem['candidates']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_docs,train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPred = model.predict(train_docs);\n",
    "trainMetrics = model.metrics_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(zip(train_labels,trainPred), columns=['label','pred'])\n",
    "df.label = df.label.apply(lambda x: int(re.sub(r'\\D','',x)));\n",
    "df.pred = df.pred.apply(lambda x: int(re.sub(r'\\D','',x)));\n",
    "df.plot.scatter(x='label',y='pred');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m  = trainMetrics\n",
    "df = pd.DataFrame([item for s in m for item in s])\n",
    "df['doc']      = [i               for i,s in enumerate(m) for item in s]\n",
    "df['solution'] = [train_labels[i] for i,s in enumerate(m) for item in s]\n",
    "df.sort_values(by=['doc','similarityNorm', 'manhattan'], ascending=[True,False,True], inplace=True)\n",
    "df['distance'] = [i for i in range(len(set(train_labels)))]* len(trainMetrics)\n",
    "df[df.doc == 55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.bestMatch].copy();\n",
    "df2['correct'] = df2.apply(lambda x: x['label'] == x['solution'], axis=1)\n",
    "df2[['correct','doc']].groupby(by='correct').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df[df.bestMatch].copy();\n",
    "df2['correct'] = df2.apply(lambda x: x['label'] == x['solution'], axis=1)\n",
    "df2[['correct','doc']].groupby(by='correct').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.solution == df.label].plot.scatter(x='distance', y='manhattanNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='distance', y='guassianNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='distance', y='similarityNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='manhattanNorm', y='guassianNorm', c='distance',colormap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from baseline\n",
    "gt = {}\n",
    "with open(pathjoin(inputDir, problem['problem'], 'ground-truth.json'), 'r') as f:\n",
    "    for attrib in json.load(f)['ground_truth']:\n",
    "        gt[attrib['unknown-text']] = attrib['true-author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs, _, test_filename = zip(*problem['unknown'])\n",
    "test_labels = [gt[v] for v in test_filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testPred = model.predict(test_docs);\n",
    "testMetrics = model.metrics_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m  = testMetrics\n",
    "df = pd.DataFrame([item for s in m for item in s])\n",
    "df['doc']      = [i               for i,s in enumerate(m) for item in s]\n",
    "df['solution'] = [train_labels[i] for i,s in enumerate(m) for item in s]\n",
    "df.sort_values(by=['doc','similarityNorm', 'KLD'], ascending=[True,False,True], inplace=True)\n",
    "df['distance'] = [i for i in range(len(set(train_labels)))]* len(testMetrics)\n",
    "df[df.doc == 55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,precision,recall,accuracy =  eval_measures(gt,{k: v for k,v in zip(test_filename, testPred)  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{\n",
    "                'macro-f1'       : round(f1,3),\n",
    "                'macro-precision': round(precision,3),\n",
    "                'macro-recall'   : round(recall,3),\n",
    "                'micro-accuracy' : round(accuracy,3)\n",
    "             }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.bestMatch].copy();\n",
    "df2['correct'] = df2.apply(lambda x: x['label'] == x['solution'], axis=1)\n",
    "df2[['correct','doc']].groupby(by='correct').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.solution == df.label].plot.scatter(x='distance', y='guassianNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='distance', y='manhattanNorm')\n",
    "df[df.solution == df.label].plot.scatter(x='distance', y='similarityNorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.solution == df.label]\\\n",
    "    .plot\\\n",
    "    .scatter(\n",
    "        x='guassianNorm',\n",
    "        y='similarityNorm',\n",
    "        c='distance',\n",
    "        colormap='Reds',\n",
    "        figsize=(20,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
